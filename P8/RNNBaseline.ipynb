{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import p8_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tf.losses.Reduction)\n",
    "#help(tf.reduce_mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './tmp/rnn'\n",
    "OUTPUT_DIR_TB = './tmp'\n",
    "datadir = './data'\n",
    "is_tensorboard = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will kill the processes for Tensorboard\n",
    "#is_tensorboard = True\n",
    "if is_tensorboard is True :\n",
    "    !ps aux | grep tensorboard | awk '{print $2}' | xargs kill\n",
    "# this will kill the processes for ngrok\n",
    "if is_tensorboard is True :\n",
    "    !ps aux | grep ngrok | awk '{print $2}' | xargs kill    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p8_util\n",
    "filename_dataset=None\n",
    "x_train, x_valid, x_test, y_train, y_valid, y_test, nClasses, tuple_dimension = p8_util.load_dataset(filename_dataset, dataset_type='MNIST')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p8_util_config\n",
    "import NNAdaNetBuilder\n",
    "\n",
    "#-----------------------------------------------------------------\n",
    "# Get the number of convolutional layers for CNN network\n",
    "# This will fixe the equivalent parameter of AdaNet num layers.\n",
    "#-----------------------------------------------------------------\n",
    "layer_num = p8_util_config.dict_adanet_config['adanet_nn_layer_config']['nn_layer_config']['rnn_layer_num']\n",
    "print(\"\\n Number of layers= {}\".format(layer_num))\n",
    "oNNAdaNetBuilder = NNAdaNetBuilder.NNAdaNetBuilder(p8_util_config.dict_adanet_config, num_layers=layer_num)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oNNAdaNetBuilder.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters that will be provided to model_fn\n",
    "import p8_util_config    X_seq = tf.unstack(X, axis=1) # shape: [batch_size, i, n_inputs], total num of i = n_steps\n",
    "\n",
    "nn_type = p8_util_config.dict_adanet_config['adanet_nn_layer_config']['nn_type']\n",
    "\n",
    "\n",
    "params = {'net_builder':oNNAdaNetBuilder, 'nn_type':nn_type}\n",
    "print(\"\\n NN Type= {}\".format(nn_type))\n",
    "my_config = p8_util.make_config(nn_type,output_dir=OUTPUT_DIR, is_restored=False)  \n",
    "\n",
    "classifier = tf.estimator.Estimator(model_fn=p8_util.my_model_fn, params=params, config=my_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_time = time.time()\n",
    "results, _ = tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "        input_fn=p8_util.input_fn(\"train\", x_train, y_train, p8_util_config.NUM_EPOCHS\\\n",
    "                          , tuple_dimension=tuple_dimension\\\n",
    "                          , batch_size=p8_util_config.BATCH_SIZE),\n",
    "        max_steps=p8_util_config.MAX_STEPS),\n",
    "    \n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "        input_fn=p8_util.input_fn(\"test\", x_test, y_test, p8_util_config.NUM_EPOCHS\\\n",
    "                           , tuple_dimension=tuple_dimension\\\n",
    "                           , batch_size=p8_util_config.BATCH_SIZE),\n",
    "        steps=None,\n",
    "        throttle_secs=1))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(2, 3)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "import numpy as np\n",
    "\n",
    "X_data = np.array([\n",
    "# steps   1st     2nd       3rd\n",
    "        [[1, 2], [7, 8], [13, 14]],   # first batch\n",
    "        #  <-- n_input -->\n",
    "        [      [3, 4],       [9, 10], [15, 16]],  # second batch\n",
    "        [      [5, 6],       [11, 12], [17, 18]], # third batch\n",
    "        [      [1, 0],       [1, 12], [7, 8]]     # fourth batch\n",
    "])\n",
    "#help(tf.unstack)\n",
    "X_data.shape\n",
    "n_inputs = X_data.shape[2]\n",
    "n_steps = X_data.shape[1]\n",
    "n_inputs, n_steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "X_seq shape [batch_size, n_steps, n_inputs]:  [3 4 2]\n",
      "\n",
      "Output shape [batch_size, n_neurons]:  [3 4 8]\n",
      "\n",
      "State shape [batch_size, n_neurons]:  [4 8]\n",
      "\n",
      "Output_st shape [batch_size, n_steps, n_neurons]:  [4 3 8]\n",
      "\n",
      "Is the output of X2 equals to the state?  True\n"
     ]
    }
   ],
   "source": [
    "# hyperparameters\n",
    "n_neurons = 8\n",
    "\n",
    "# parameters\n",
    "n_inputs = X_data.shape[2]\n",
    "n_steps = X_data.shape[1]\n",
    "\n",
    "# rnn model\n",
    "X = tf.placeholder(tf.float32, [None, n_steps, n_inputs])\n",
    "X_seq = tf.unstack(X, axis=1) # shape: [batch_size, i, n_inputs], total num of i = n_steps\n",
    "\n",
    "\n",
    "\n",
    "#XT_data = tf.transpose(X_data, [1, 0, 2]) \n",
    "#X_seq = tf.unstack(XT_data, axis=1) # shape: [batch_size, i, n_inputs], total num of i = n_steps\n",
    "\n",
    "\n",
    "cell = tf.keras.layers.SimpleRNNCell(units=n_neurons)\n",
    "# Here under, a static graph is created with n_neurons cells.\n",
    "output, state = tf.nn.static_rnn(cell, X_seq, dtype=tf.float32)\n",
    "X_seq = tf.unstack(X, axis=1) # shape: [batch_size, i, n_inputs], total num of i = n_steps\n",
    "\n",
    "output_st = tf.stack(output, axis=1)\n",
    "\n",
    "\n",
    "# initialize the variables\n",
    "init = tf.global_variables_initializer()\n",
    "\n",
    "# train\n",
    "with tf.Session() as sess:\n",
    "    sess.run(init)\n",
    "    # X, input shape: (batch_size, time_step_size, input_vec_size)\n",
    "    #X_data = tf.transpose(X_data, [1, 0, 2])  # permute time_step_size and batch_size\n",
    "    feed_dict = {X: X_data}\n",
    "    \n",
    "    # print the shape\n",
    "    if True :\n",
    "        \n",
    "        X_seq_shape = sess.run(tf.shape(X_seq), feed_dict=feed_dict)\n",
    "        output_shape = sess.run(tf.shape(output), feed_dict=feed_dict)\n",
    "        state_shape = sess.run(tf.shape(state), feed_dict=feed_dict)\n",
    "        output_st_shape = sess.run(tf.shape(output_st), feed_dict=feed_dict)\n",
    "\n",
    "        print('\\nX_seq shape [batch_size, n_steps, n_inputs]: ', X_seq_shape)\n",
    "        print('\\nOutput shape [batch_size, n_neurons]: ', output_shape)\n",
    "        print('\\nState shape [batch_size, n_neurons]: ', state_shape)\n",
    "        print('\\nOutput_st shape [batch_size, n_steps, n_neurons]: ', output_st_shape)\n",
    "    \n",
    "    output_eval, state_eval = sess.run([output, state], feed_dict=feed_dict)\n",
    "    \n",
    "    print('\\nIs the output of X2 equals to the state? ', np.array_equal(output_eval[2], state_eval))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(state_eval)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_tensorboard is True :\n",
    "    get_ipython().system_raw(\n",
    "        'tensorboard --logdir {} --host localhost --port 6006 &'\n",
    "        .format(OUTPUT_DIR_TB)\n",
    "    )\n",
    "\n",
    "\n",
    "    get_ipython().system_raw('./assets/ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
