{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "import time\n",
    "import tensorflow as tf\n",
    "import p8_util"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR = './tmp/baseline'\n",
    "datadir = './data'\n",
    "is_tensorboard = False\n",
    "\n",
    "if is_tensorboard is True :\n",
    "    get_ipython().system_raw(\n",
    "        'tensorboard --logdir {} --host localhost --port 6006 &'\n",
    "        .format(OUTPUT_DIR)\n",
    "    )\n",
    "\n",
    "\n",
    "    get_ipython().system_raw('./assets/ngrok http 6006 &')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# this will kill the processes for Tensorboard\n",
    "if is_tensorboard is True :\n",
    "    !ps aux | grep tensorboard | awk '{print $2}' | xargs kill\n",
    "# this will kill the processes for ngrok\n",
    "if is_tensorboard is True :\n",
    "    !ps aux | grep ngrok | awk '{print $2}' | xargs kill    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/arr_keras_X_y_train_test.dump\n"
     ]
    }
   ],
   "source": [
    "import p8_util\n",
    "filename_dataset=datadir+'/arr_keras_X_y_train_test.dump'\n",
    "x_train, x_test, y_train, y_test, nClasses, tuple_dimension = p8_util.load_dataset(filename_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import keras\n",
    "\n",
    "LEARNING_RATE = 5.e-4\n",
    "nn_type = 'CNN'\n",
    "nb_class = nClasses\n",
    "my_feature_columns, loss_reduction, tf_head = p8_util.get_tf_head(\"images\",tuple_dimension, nClasses)\n",
    "feature_columns = my_feature_columns\n",
    "\n",
    "optimizer=tf.train.RMSPropOptimizer(learning_rate=LEARNING_RATE)\n",
    "#optimizer = tf.train.AdagradOptimizer(learning_rate=LEARNING_RATE)\n",
    "#optimizer = keras.optimizers.SGD(lr=LEARNING_RATE, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "layer_size = 50\n",
    "num_layers = 3\n",
    "learn_mixture_weights = False\n",
    "dropout = 0.5\n",
    "seed=p8_util.RANDOM_SEED\n",
    "is_cnn_batch_norm = True\n",
    "cnn_layer_config={'feature_map_size':[128]}\n",
    "initialiser_name = 'xavier'\n",
    "oNNAdaNetBuilder = p8_util._NNAdaNetBuilder(nn_type, nb_class,feature_columns, optimizer, layer_size, num_layers,\n",
    "               learn_mixture_weights, dropout, seed, is_cnn_batch_norm,cnn_layer_config, initialiser_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tf.train.get_global_step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Using config: {'_model_dir': './tmp/baseline/CNN', '_tf_random_seed': 42, '_save_summary_steps': 5, '_save_checkpoints_steps': 5, '_save_checkpoints_secs': None, '_session_config': allow_soft_placement: true\n",
      "graph_options {\n",
      "  rewrite_options {\n",
      "    meta_optimizer_iterations: ONE\n",
      "  }\n",
      "}\n",
      ", '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000, '_log_step_count_steps': 100, '_train_distribute': None, '_device_fn': None, '_protocol': None, '_eval_distribute': None, '_experimental_distribute': None, '_service': None, '_cluster_spec': <tensorflow.python.training.server_lib.ClusterSpec object at 0x7f41a6896668>, '_task_type': 'worker', '_task_id': 0, '_global_id_in_cluster': 0, '_master': '', '_evaluation_master': '', '_is_chief': True, '_num_ps_replicas': 0, '_num_worker_replicas': 1}\n",
      "INFO:tensorflow:Not using Distribute Coordinator.\n",
      "INFO:tensorflow:Running training and evaluation locally (non-distributed).\n",
      "INFO:tensorflow:Start train and evaluate loop. The evaluate will happen after every checkpoint. Checkpoint frequency is determined based on RunConfig arguments: save_checkpoints_steps 5 or save_checkpoints_secs None.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Saving checkpoints for 0 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:loss = 1.2714821, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 5 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-17-13:43:48\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/baseline/CNN/model.ckpt-5\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-17-13:43:51\n",
      "INFO:tensorflow:Saving dict for global step 5: eval_accuracy = 0.31914893, global_step = 5, loss = 1.0986212\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 5: ./tmp/baseline/CNN/model.ckpt-5\n",
      "INFO:tensorflow:Saving checkpoints for 10 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-17-13:44:31\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/baseline/CNN/model.ckpt-10\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-17-13:44:33\n",
      "INFO:tensorflow:Saving dict for global step 10: eval_accuracy = 0.38297874, global_step = 10, loss = 1.0985421\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 10: ./tmp/baseline/CNN/model.ckpt-10\n",
      "INFO:tensorflow:Saving checkpoints for 15 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-17-13:45:14\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/baseline/CNN/model.ckpt-15\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-17-13:45:17\n",
      "INFO:tensorflow:Saving dict for global step 15: eval_accuracy = 0.44680852, global_step = 15, loss = 1.0981711\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 15: ./tmp/baseline/CNN/model.ckpt-15\n",
      "INFO:tensorflow:Saving checkpoints for 20 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-17-13:45:58\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/baseline/CNN/model.ckpt-20\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-17-13:46:00\n",
      "INFO:tensorflow:Saving dict for global step 20: eval_accuracy = 0.38297874, global_step = 20, loss = 1.0982716\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 20: ./tmp/baseline/CNN/model.ckpt-20\n",
      "INFO:tensorflow:Saving checkpoints for 25 into ./tmp/baseline/CNN/model.ckpt.\n",
      "INFO:tensorflow:Calling model_fn.\n",
      "INFO:tensorflow:Done calling model_fn.\n",
      "INFO:tensorflow:Starting evaluation at 2019-04-17-13:46:39\n",
      "INFO:tensorflow:Graph was finalized.\n",
      "INFO:tensorflow:Restoring parameters from ./tmp/baseline/CNN/model.ckpt-25\n",
      "INFO:tensorflow:Running local_init_op.\n",
      "INFO:tensorflow:Done running local_init_op.\n",
      "INFO:tensorflow:Finished evaluation at 2019-04-17-13:46:42\n",
      "INFO:tensorflow:Saving dict for global step 25: eval_accuracy = 0.34042552, global_step = 25, loss = 1.0985436\n",
      "INFO:tensorflow:Saving 'checkpoint_path' summary for global step 25: ./tmp/baseline/CNN/model.ckpt-25\n"
     ]
    }
   ],
   "source": [
    "# Parameters that will be provided to model_fn\n",
    "BATCH_SIZE = 50  #@param {type:\"integer\"}\n",
    "MAX_STEPS = 200\n",
    "params = {'learning_rate':LEARNING_RATE, 'net_builder':oNNAdaNetBuilder}\n",
    "NN_TYPE = 'CNN'\n",
    "my_config = p8_util.make_config(NN_TYPE,output_dir=OUTPUT_DIR, is_restored=False)  \n",
    "NUM_EPOCHS = 2\n",
    "classifier = tf.estimator.Estimator(model_fn=p8_util.my_model_fn, params=params, config=my_config)\n",
    "start_time = time.time()\n",
    "results, _ = tf.estimator.train_and_evaluate(\n",
    "    classifier,\n",
    "    train_spec=tf.estimator.TrainSpec(\n",
    "        input_fn=p8_util.input_fn(\"train\", x_train, y_train, NUM_EPOCHS\\\n",
    "                          , tuple_dimension=tuple_dimension\\\n",
    "                          , batch_size=BATCH_SIZE),\n",
    "        max_steps=MAX_STEPS),\n",
    "    \n",
    "    eval_spec=tf.estimator.EvalSpec(\n",
    "        input_fn=p8_util.input_fn(\"test\", x_test, y_test, NUM_EPOCHS\\\n",
    "                           , tuple_dimension=tuple_dimension\\\n",
    "                           , batch_size=BATCH_SIZE),\n",
    "        steps=None,\n",
    "        throttle_secs=1))\n",
    "end_time = time.time()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n------------------------------------------------\")\n",
    "print(\"Time (sec)\", end_time-start_time)\n",
    "for key in results.keys() :\n",
    "    title =key.upper()\n",
    "    print(\"{}: {}\".format(title, results[key]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(tf.estimator.EstimatorSpec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "OUTPUT_DIR"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
