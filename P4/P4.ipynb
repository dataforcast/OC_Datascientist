{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "<p>\n",
    "Cette étude a été réalisée dans le cadre du 4eme projet de ma formation Datascientist dispensée en MOOC par \n",
    "**<font color='blus'>Openclassrooms / écoles Centrale-Supélec</font>**.\n",
    "</p>    \n",
    "\n",
    "<p>\n",
    "Ce notebook présente un modèle de prédiction des retards d'avions. \n",
    "</p>\n",
    "<p>\n",
    "Le modèle se base sur les données fournies par le site :\n",
    "</p>\n",
    "<p>\n",
    "https://www.transtats.bts.gov/DL_SelectFields.asp?Table_ID=236&DB_Short_Name=On-Time\n",
    "</p>\n",
    "<p>\n",
    "</p>\n",
    "</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'> Synthèse du 24/05/2018</font>\n",
    "\n",
    "## <font color='blue'>Nature du pb à résoudre</font>\n",
    "* Problème de prédiction.\n",
    "* Orientation vers un algorithme de régression.\n",
    "\n",
    "## <font color='blue'>Acquisition des données</font>\n",
    "* Problème de débordement mémoire\n",
    "\n",
    "## <font color='blue'>Préparation des données</font>\n",
    "* Traitement des valeurs a Nan\n",
    "\n",
    "## <font color='blue'>Analyse exploratoire</font>\n",
    "Objectifs: appréhender la nature du problème à résoudre pour s'orienter vers des modèles de prédictions.\n",
    "* Correlations\n",
    "* Analyse en composantes principales :  quelles sont les variables qui expliquent le plus la variance? Réduction de dimension possible?\n",
    "\n",
    "## <font color='blue'>Evaluation des modèles de prédiction</font>\n",
    "* Modèle linéaire : basé sur une combinaison linéaire des variables.__Comment justifier l'hyopthèse de linéarité?__\n",
    "* Choix des hyper-paramètres : Grid search\n",
    "* Entraînement des modèles : validation croisée\n",
    "* Prédiction des retards avec un score : prédiction de la valeur du retard\n",
    "* Prédiction binaire du retard : en retard / pas en retard\n",
    "* Comparaison des performances avec des modèles naïfs.\n",
    "* Augmentation de la performance des algorithmes évalués\n",
    "\n",
    "## <font color='blue'>Choix du modèle de prédiction</font>\n",
    "\n",
    "\n",
    "* Anticiper les retards : retard = heure atterissage - heure prévue.\n",
    "* Créer la colonne avant la séparation et supprimer la colonne dont elle dépend. Sinon phénomène de __DATA LEAKAGE__. *En effet, si on utilise deux variables pour en créer une 3eme, alors lorsque l'on va prédire, à un instant dans le futur, une valeur pour cette 3eme variable, les valeurs des 2 variables utilisées ne seront plus valables au moment de la prédiction. Les variables ayant servies à créer cette nouvelle variable doivent être **exclues du modèle**.*.\n",
    "\n",
    "* Les étiquettes sont a valeurs dans les réels. On utilisera donc une regression linéaire pour la prédiction des retards.\n",
    "\n",
    "* Après modélisation, si la mtrice X.T.dot(X) est inversible, alors le pb admet une solution unique et explicite, issue de la maximisation de la vraissemblance du modèle, i.e, la maximisation de la probabilité de calculer la valeur de la cible (ici, pour ce problème, les retards).\n",
    "\n",
    "* Technique courante sur les lignes : définir les indices das un vecteur modele réduit Etudier l'impact de la taille des données d'entraînement sur la qualité de la prédiction. 20%, 40%, 30% de l'entraînement et regarder la performance.\n",
    "* Supprimer les colones qui n'apporent rien a la prediction\n",
    "* Regression : foncton de out a optimiser va inclure les coeff de Ridge de et Lasso Initialement, sans regularisation. Par la suite, essayer la recherche d'hyper-paramètres l1 et l2 qui controlent Ridge et Lasso. __Coder une seule loss__ qui jauge l'effet de la régularisation L1 et L2. __==> utiliser la regression elestic net.__\n",
    "\n",
    "* Conclusion : jouer le jeux de test et évaluer l'erreur quadratique.\n",
    "\n",
    "* __Le pb est formulé en prédiction__ : entraîner un modele sur Janv--> mars, essayer sur Avril. Ce, pour répondre a la probléamatique : évaluer les retards dans le futur.\n",
    "* Entraîner surr 15 premiers jours et tester sur les derniers jours.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'> Synthèse du 19/05/2018</font>\n",
    "\n",
    "## <font color='blue'>Acquisition des données</font>\n",
    "* Exploration des données et modèle sur un mois\n",
    "\n",
    "## <font color='blue'>Préparation des données</font>\n",
    "* Traitement des valeurs a Nan remplacées par la valeur moyenne dans le vecteur étiquette \n",
    "* Mises a 0 sur les autres données.\n",
    "\n",
    "## <font color='blue'>Analyse exploratoire</font>\n",
    "Objectifs: appréhender la nature du problème à résoudre pour s'orienter vers des modèles de prédictions.\n",
    "* Correlations : données corrélées sur les retards ==> élimination des colonnes corrélées?\n",
    "\n",
    "## <font color='blue'>Evaluation d'un modèle de prédiciton binaire : KNN</font>\n",
    "* Choix des hyper-paramètres : Grid search\n",
    "* Entraînement des modèles : validation croisée\n",
    "* Affichage des performances du modèle : MSE et matrice de confusion\n",
    "\n",
    "## <font color='blue'>Modèle de prédiction par regression : SVR </font>\n",
    "* Données d'entraînement : sur un mois, les 3 premières semaines.\n",
    "* Regression linéaire par vecteur de support\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Acquisition des données</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading Python lib used for project__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from p3_util import *\n",
    "from p3_util_plot import *\n",
    "from p4_util import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Data loading from a fixed month__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "path_name = \"./data/Dataset+Projet+4/2016\"\n",
    "month = '03'\n",
    "\n",
    "path_name_month = path_name+\"_\"+str(month)+\".csv\"\n",
    "df_dealays = pd.read_csv(path_name_month, delimiter=',',low_memory=False)\n",
    "print(\"Month \"+month+\" loaded!\")\n",
    "print(df_dealays.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Loading remainings month__"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "list_month=['02','03','04','05','06']\n",
    "\n",
    "# Loading remaining months against list_month\n",
    "for month in list_month :\n",
    "    path_name_month = path_name+\"_\"+str(month)+\".csv\"\n",
    "    df_dealays = df_dealays.add(pd.read_csv(path_name_month, delimiter=','))\n",
    "    print(\"Month \"+month+\" loaded!\")\n",
    "    print(df_dealays.shape)\n",
    "    print(df_dealays.columns)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_dealays.shape)\n",
    "print(df_dealays.columns)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "sampling=10\n",
    "df_dealays.AIRLINE_ID.sample(sampling),\\\n",
    "df_dealays.WEATHER_DELAY.sample(sampling),\\\n",
    "df_dealays.NAS_DELAY.sample(sampling),\\\n",
    "df_dealays.SECURITY_DELAY.sample(sampling),\\\n",
    "df_dealays.LATE_AIRCRAFT_DELAY.sample(sampling)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Data preparation</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Nan values processing__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Getting digital dataframe with ditigal columns only\n",
    "print(df_dealays.shape)\n",
    "\n",
    "df_dealays_digit,list_col_notdigit = df_get_digital_columns(df_dealays) \n",
    "print(df_dealays_digit.shape)\n",
    "print(list_col_notdigit)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealays_digit_sample = df_dealays_digit.sample(int(df_dealays.shape[0]/10))\n",
    "\n",
    "df_dealays_digit_sample.columns\n",
    "df_dealays_digit_sample_restricted = df_dealays_digit_sample.iloc[:,:-9]\n",
    "df_dealays_digit_sample_restricted.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealays_digit_sample_cleaned , list_dropped_unique= df_clean_nan(df_dealays_digit_sample_restricted, verbose=False, action=True)\n",
    "list_dropped_unique"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Exploratory analysis</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__ PCA : data are scaled __"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dropped_unique"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_scaled_ = df_pca_all_plot(df_dealays_digit_sample_cleaned)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get standardized data\n",
    "X_scaled = df_get_std_scaled_values(df_dealays_digit_sample_cleaned)\n",
    "\n",
    "#Build PCA algorithme.\n",
    "nb_components = 2\n",
    "pca = PCA(n_components=nb_components)\n",
    "pca.fit(X_scaled)\n",
    "\n",
    "X_projected = pca.transform(X_scaled)\n",
    "print(X_projected.shape)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_pcs2_plot(df_dealays_digit_sample_cleaned, pca)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealays_digit_sample_cleaned_corr = df_dealays_digit_sample_cleaned.corr()\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "_z = sns.heatmap(df_dealays_digit_sample_cleaned_corr, annot=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Analyse des variables liées aux retards</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig = plt.figure(figsize=(16, 16))\n",
    "list_data= ['DEP_DELAY',\n",
    "       'DEP_DELAY_NEW', 'DEP_DEL15', 'DEP_DELAY_GROUP', 'TAXI_OUT',\n",
    "       'WHEELS_OFF', 'WHEELS_ON', 'TAXI_IN', 'CRS_ARR_TIME', 'ARR_TIME',\n",
    "       'ARR_DELAY', 'ARR_DELAY_NEW', 'ARR_DEL15', 'ARR_DELAY_GROUP',\n",
    "       'CANCELLED', 'DIVERTED', 'CRS_ELAPSED_TIME', 'ACTUAL_ELAPSED_TIME']\n",
    "if True :\n",
    "    for pos in range(len(list_data)) :\n",
    "        item = list_data[pos]\n",
    "        X = df_dealays_digit_sample_cleaned[item]\n",
    "        ax = fig.add_subplot(5,4, (pos+1))\n",
    "        h = ax.hist(X, bins=50, color='steelblue', edgecolor='none', normed=True)\n",
    "        ax.set_title(item, fontsize=8)\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Corrrelation des varables liées aux retards__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_data\n",
    "df = pd.DataFrame()\n",
    "ser1 = df_dealays_digit_sample_cleaned['DEP_DELAY']\n",
    "\n",
    "ser2 = df_dealays_digit_sample_cleaned['ACTUAL_ELAPSED_TIME']\n",
    "result = pd.concat([ser1, ser2], axis=1)\n",
    "for column in list_data :\n",
    "    ser = df_dealays_digit_sample_cleaned[column]\n",
    "    df = pd.concat([df, ser], axis=1)\n",
    "\n",
    "    \n",
    "df_corr = df.corr()    \n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "_z = sns.heatmap(df_corr, annot=False)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "pca = df_pca_components_plot(df_dealays_digit_sample_cleaned, 'MONTH')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Classification binaire KNN : ARR_DELAY </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imputation des valeurs a la moyenne pour la classe binaire issue de la colonne ARR_DELAY__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_arr_delay = df_dealays_digit_sample_restricted.ARR_DELAY\n",
    "arr_delay = np.array(ser_arr_delay)\n",
    "\n",
    "where_nan_index = np.isnan(arr_delay)\n",
    "array_delay_sum = np.nansum(arr_delay)\n",
    "mean_delay_sum = array_delay_sum/len(arr_delay)\n",
    "\n",
    "arr_delay[where_nan_index] = mean_delay_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealays_digit_sample_restricted.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creation de la classe binaire : retard ou pas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = np.where(arr_delay>0,1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imputation des valeurs indéfinies à 0 dans le dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = df_dealays_digit_sample_restricted.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purge de la colonne ARR_DELAY__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df.shape)\n",
    "X = df.drop(labels='ARR_DELAY', axis=1)\n",
    "print(X.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Création des jeux de données d'entraînement et de test sur des données standardisées__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.33)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Standardisation des données__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X_train)\n",
    "X_train_std = std_scale.transform(X_train)\n",
    "X_test_std = std_scale.transform(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recherche du nb de voisins optimum du KNN par validation croisée__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import cross_val_score\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Creation d'une liste de nombre de voisins impairs\n",
    "#-----------------------------------------------------------------------------------\n",
    "myList = list(range(3,6))\n",
    "\n",
    "neighbors = filter(lambda x: x % 2 != 0, myList)\n",
    "list_neighbors = list(neighbors)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Liste contenant les scores moyens de la recherche croisée (CV)\n",
    "#-----------------------------------------------------------------------------------\n",
    "list_cv_mean_scores = list()\n",
    "\n",
    "min_index = 0\n",
    "scores_mean = 0.0\n",
    "import time\n",
    "t0 = time.time()\n",
    "# Recherche du nombre de voisins optimumss\n",
    "for k in list_neighbors:\n",
    "    knn_clf = KNeighborsClassifier(n_neighbors=k)\n",
    "    scores = cross_val_score(knn_clf, X_train_std, y_train, cv=5, scoring='accuracy')\n",
    "    list_cv_mean_scores.append(scores.mean())\n",
    "print(\"KNN : recherche du nombre de voisins optimum = %0.3fs\" % (time.time()-t0))\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Erreur de classification minimale\n",
    "#-----------------------------------------------------------------------------------\n",
    "list_mse = [1 - x for x in list_cv_mean_scores]\n",
    "min_index = list_mse.index(min(list_mse))\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Extraction du meilleur nombre de voisins\n",
    "#-----------------------------------------------------------------------------------\n",
    "optimal_k = list_neighbors[min_index]\n",
    "print( \"Le nombre optimal de voisins est %d\" % optimal_k)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# plot misclassification error vs k\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.plot(list_neighbors, list_mse)\n",
    "plt.xlabel('Nombre de voisins K')\n",
    "plt.ylabel('Erreur de classification')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Prédictions avec un classifieur KNN optimal__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=5)\n",
    "t0 = time.time()\n",
    "knn_clf.fit(X_train_std, y_train)\n",
    "t1 = time.time()\n",
    "print(\"Apprentissage KNN réalisé en %0.3Fs\" % (t1-t0))\n",
    "y_pred_knn = knn_clf.predict(X_test_std)\n",
    "print(\"Meilleur score pour la classification KNN : %0.4F\" % accuracy_score(y_test, y_pred_knn))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Affichage des scores du classificateur binaire__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import classification_report\n",
    "from sklearn.metrics import confusion_matrix\n",
    "print(y_test.shape)\n",
    "class_names=['RETARD','PONCTUEL']\n",
    "print(classification_report(y_test, y_pred_knn,target_names=class_names))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Affichage graphique de la matrice de confusions__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import itertools\n",
    "\n",
    "def plot_confusion_matrix(cm, classes,\n",
    "                          normalize=False,\n",
    "                          title='Confusion matrix',\n",
    "                          cmap=plt.cm.Blues):\n",
    "    \"\"\"\n",
    "    This function prints and plots the confusion matrix.\n",
    "    Normalization can be applied by setting `normalize=True`.\n",
    "    \"\"\"\n",
    "    if normalize:\n",
    "        cm = cm.astype('float') / cm.sum(axis=1)[:, np.newaxis]\n",
    "        print(\"Normalized confusion matrix\")\n",
    "    else:\n",
    "        print('Confusion matrix, without normalization')\n",
    "\n",
    "    print(cm)\n",
    "    plt.figure(figsize=(8,8))\n",
    "    plt.imshow(cm, interpolation='nearest', cmap=cmap)\n",
    "    plt.title(title)\n",
    "    plt.colorbar()\n",
    "    tick_marks = np.arange(len(classes))\n",
    "    plt.xticks(tick_marks, classes, rotation=45)\n",
    "    plt.yticks(tick_marks, classes)\n",
    "\n",
    "    fmt = '.2f' if normalize else 'd'\n",
    "    thresh = cm.max() / 2.\n",
    "    for i, j in itertools.product(range(cm.shape[0]), range(cm.shape[1])):\n",
    "        plt.text(j, i, format(cm[i, j], fmt),\n",
    "                 horizontalalignment=\"center\",\n",
    "                 color=\"white\" if cm[i, j] > thresh else \"black\")\n",
    "\n",
    "    plt.tight_layout()\n",
    "    plt.ylabel('True label')\n",
    "    plt.xlabel('Predicted label')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test, y_pred_knn )\n",
    "#print(conf)\n",
    "plot_confusion_matrix(conf, class_names,\n",
    "                          normalize=True,\n",
    "                          title='Matrice de confusion',\n",
    "                          cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import matplotlib.pyplot as plt\n",
    "n_classes = 2\n",
    "conf = confusion_matrix(y_test, y_pred_knn)\n",
    "plt.figure(figsize=(10,10))\n",
    "plt.xlabel('Classe réelle')\n",
    "plt.ylabel('Classe prédite')\n",
    "\n",
    "plt.imshow(conf, cmap='binary', interpolation='None')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Classification binaire KNN : calcul du retard </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_dealays_digit_sample_restricted.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Groupement des résultats par airline ID</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Recupération des identifiants de compagines__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_airline_id = df_dealays_digit_sample_restricted.AIRLINE_ID.unique()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Stockage des DF dans un dictionnaire de compagnies__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_df_aid=dict()\n",
    "df = df_dealays_digit_sample_restricted.copy()\n",
    "for aid in arr_airline_id :\n",
    "    dict_df_aid[aid] = df[df['AIRLINE_ID']==aid]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Classifieur KNN : recherche du meilleur nombre de voisins pour le dernier aid__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = dict_df_aid[aid]\n",
    "df_aid.columns\n",
    "#df_aid['DAY_OF_MONTH']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_delay = df_aid.ARR_DELAY\n",
    "arr_delay = np.array(ser_delay)\n",
    "where_nan_index = np.isnan(arr_delay)\n",
    "\n",
    "array_delay_sum = np.nansum(arr_delay)\n",
    "mean_delay_sum = array_delay_sum/len(arr_delay)\n",
    "\n",
    "arr_delay[where_nan_index] = mean_delay_sum"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Creation de la classe binaire : retard ou pas__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aid = np.where(arr_delay>0,1,-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Imputation des valeurs indéfinies à 0 dans le dataframe__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = df_aid.fillna(value=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purge de la colonne ARR_DELAY__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_aid.shape)\n",
    "X_aid = df_aid.drop(labels='ARR_DELAY', axis=1)\n",
    "print(X_aid.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Création des jeux de données d'entraînement et de test sur des données standardisées__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "X_train_aid, X_test_aid, y_train_aid, y_test_aid = train_test_split(X_aid, y_aid, test_size=0.20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Standardisation des données__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "std_scale = preprocessing.StandardScaler().fit(X_train_aid)\n",
    "X_train_aid_std = std_scale.transform(X_train_aid)\n",
    "X_test_aid_std = std_scale.transform(X_test_aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "best_neighbors = knn_cv_search(X_train_aid_std, y_train_aid, list_neighbors=None, cv_parameter=5\\\n",
    "   , scoring_parameter='accuracy')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "knn_clf = KNeighborsClassifier(n_neighbors=best_neighbors)\n",
    "t0 = time.time()\n",
    "knn_clf.fit(X_train_aid_std, y_train_aid)\n",
    "t1 = time.time()\n",
    "print(\"Apprentissage KNN réalisé en %0.3Fs\" % (t1-t0))\n",
    "y_pred_aid_knn = knn_clf.predict(X_test_aid_std)\n",
    "print(\"Meilleur score pour la classification KNN de la compagine= {} : {}\".format(aid,accuracy_score(y_test_aid, y_pred_aid_knn)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "conf = confusion_matrix(y_test_aid, y_pred_aid_knn )\n",
    "class_names=['RETARD','PONCTUEL']\n",
    "title_aid = 'Matrice de confusion des retards : compagnie= {}'.format(aid)\n",
    "\n",
    "if True :\n",
    "    plot_confusion_matrix(conf, class_names,\n",
    "                              normalize=True,\n",
    "                              title = title_aid,\n",
    "                              cmap=plt.cm.Reds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blues'>Regression sur les valeurs des retards </font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Modèle de regression SVR</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Validation des hypothèses: __\n",
    "* Bruit est normal\n",
    "* Obervations sont indépendantes et identiquement distribués\n",
    "* Pb est linéaire : les réalisations (X,y) doivent être rendues indépendantes les unes des autres"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blue'>Contruction d'un vecteur d'étiquettes</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Recherche du dataframe avec le max de lignes\n",
    "if False :\n",
    "    max_aid = 0\n",
    "    for aid in dict_df_aid.keys() :    \n",
    "        if dict_df_aid[aid].shape[0] > max_aid :\n",
    "            max_aid = aid\n",
    "\n",
    "    df_aid = dict_df_aid[max_aid]\n",
    "df_aid.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Traitement des valeurs a Nan par imputation de la valeur médiane__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid_save = df_aid.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid_save.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = df_aid_save.copy()\n",
    "if False :\n",
    "    for column in df_aid.columns :\n",
    "        ser = df_aid[column]\n",
    "        #median = ser.median()\n",
    "        arr_ser = np.array(ser)\n",
    "        where_nan_index = np.isnan(arr_ser)\n",
    "\n",
    "        array_sum = np.nansum(arr_ser)\n",
    "        mean_delay_sum = array_sum/len(arr_ser)\n",
    "\n",
    "        arr_ser[where_nan_index] = mean_delay_sum\n",
    "        df_aid[column] = pd.Series(arr_delay)\n",
    "else :\n",
    "    df_aid = df_aid.fillna(value=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Récupération des variables corréles selon un seuil__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid_corr = df_aid.corr()\n",
    "df_aid_corr.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "correlation_threshold_value = 0.9\n",
    "dict_dict_value_threshold = get_dict_dict_value_threshold(df_aid_corr, threshold = correlation_threshold_value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_dict_value_threshold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_corr = pd.DataFrame(dict_dict_value_threshold) \n",
    "\n",
    "f, ax = plt.subplots(figsize=(10, 10))\n",
    "_z = sns.heatmap(df_corr, annot=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aid_train, X_aid_test, y_aid_train, y_aid_test = p4_train_test_split(df_aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aid_train.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aid_train.shape, y_aid_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Standardisation des données__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import preprocessing\n",
    "if True :\n",
    "    std_scale = preprocessing.StandardScaler().fit(X_aid_train)\n",
    "    X_aid_train_std = std_scale.transform(X_aid_train)\n",
    "\n",
    "    std_scale = preprocessing.StandardScaler().fit(X_aid_test)\n",
    "    X_test_aid_std = std_scale.transform(X_aid_test)\n",
    "else :\n",
    "    X_aid_train_std = X_aid_train.copy()\n",
    "    X_aid_test_std = X_aid_test.copy()    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aid_train_std.shape, y_aid_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Regresseur linéaire : SVR__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.svm import LinearSVR\n",
    "import time\n",
    "\n",
    "lsvr_clf = LinearSVR()\n",
    "param_grid = {'C':[0.01,0.4,0.45,0.5,0.55,0.56] }\n",
    "grid_svr = GridSearchCV(lsvr_clf, param_grid, refit=True)\n",
    "t0 = time.time()\n",
    "grid_svr.fit(X_aid_train_std, y_aid_train)\n",
    "print(\"Recherche des hyper-paramètres en %0.3fs\" % (time.time() - t0))\n",
    "print(\"Meilleurs hyper-paramètres pour le classifieur LinearSVC: \"+str(grid_svr.best_params_))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "lsvr_clf = LinearSVR(C=grid_svr.best_params_['C'])\n",
    "lsvr_clf.fit(X_aid_train_std, y_aid_train)\n",
    "y_pred_aid = lsvr_clf.predict(X_test_aid_std)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test_aid_std.shape, y_pred_aid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "y_pred_aid = lsvr_clf.predict(X_test_aid_std)\n",
    "score_r2 = lsvr_clf.score(X_test_aid_std,y_aid_test)\n",
    "print(\"Coefficient de correlation R2 = %0.6f\" %score_r2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_aid_test.min(), y_aid_test.max(), y_pred_aid.min(),y_pred_aid.max()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "z_ = plt.scatter(y_aid_test, y_pred_aid, c='r', alpha=0.2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>Purge des colonnes incluant du leakage</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid.CRS_DEP_TIME.iloc[0],df_aid.DEP_TIME.iloc[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_col_drop = ['DEP_TIME','DEP_DELAY','DEP_DELAY_NEW','DEP_DEL15','DEP_DELAY_GROUP'\\\n",
    "                 ,'TAXI_OUT','WHEELS_ON','WHEELS_OFF', 'TAXI_IN','CRS_ARR_TIME','ARR_TIME'\\\n",
    "                ,'ARR_DELAY','ARR_DELAY_NEW','ARR_DEL15','ARR_DELAY_GROUP','CRS_ELAPSED_TIME'\\\n",
    "                ,'ACTUAL_ELAPSED_TIME']\n",
    "for col in list_col_drop :\n",
    "    if col in df_aid :\n",
    "        df_aid = df_aid.drop(labels=col, axis=1, inplace=False)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Purge des lignes CANCELLED=1 et DIVERTED=1__"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_aid.shape)\n",
    "df_aid_tmp = df_aid[df_aid['CANCELLED']==0]\n",
    "print(df_aid_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df_aid_tmp.shape)\n",
    "df_aid_tmp = df_aid_tmp[df_aid_tmp['DIVERTED']==0]\n",
    "print(df_aid_tmp.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_aid = df_aid_tmp.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_aid_train, X_aid_test, y_aid_train, y_aid_test = p4_train_test_split(df_aid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
