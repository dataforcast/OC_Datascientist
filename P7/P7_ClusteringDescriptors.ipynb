{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "    \n",
    "Cette étude a été réalisée dans le cadre du 6ème projet de ma formation Datascientist dispensée en MOOC par \n",
    "\n",
    "<font color='blus'>Openclassrooms / écoles Centrale-Supélec</font>.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Le problème posé :**\n",
    "\n",
    "# <font color='blus'>Indexation d'images</font>\n",
    "\n",
    "Vous êtes bénévole pour l'association de protection des animaux de votre quartier. C'est d'ailleurs ainsi que vous avez trouvé votre compagnon idéal, Snooky. Du coup, vous vous demandez ce que vous pouvez faire en retour pour aider l'association.\n",
    "\n",
    "Vous apprenez, en discutant avec un bénévole, que leur base de données de pensionnaires commence à s'agrandir et qu'ils n'ont pas toujours le temps de référencer les images des animaux qu'ils ont accumulées depuis plusieurs années. Ils aimeraient donc réaliser un index de l’ensemble de la base de données d’images qu’ils possèdent, pour classer les chiens par races.\n",
    "\n",
    "**<font color='blus'>Les données</font>**\n",
    "\n",
    "Les bénévoles de l'association n'ont pas eu le temps de réunir les différentes images des pensionnaires dispersées sur leurs disques durs. Pas de problème, vous développerez un algorithme en utilisant le Stanford Dogs Dataset pour entraîner votre algorithme.\n",
    "\n",
    "**<font color='blus'>Votre mission</font>**\n",
    "\n",
    "En tant que Data Scientist, l'association vous demande de réaliser un algorithme de détection de la race du chien sur une photo, afin d'accélérer leur travail d’indexation.\n",
    "\n",
    "**<font color='blus'>Contraintes</font>**\n",
    "\n",
    "Lors de ce projet, vous mettrez en œuvre deux approches.\n",
    "\n",
    "* Une approche classique : il s’agit de pre-processer des images avec des techniques spécifiques (e.g.whitening, equalisation, filtre linéaire/laplacien/gaussien, éventuellement modifier la taille des images), puis d’extraire des features (e.g. texture, corners, edges et SIFT detector). Il faut ensuite réduire les dimensions, soit par des approches classiques (e.g. PCA, k-means) soit avec une approche par histogrammes et dictionary learning (bag-of-words appliqué aux images), puis appliquer des algorithmes de classification standards.\n",
    "\n",
    "\n",
    "\n",
    "* Lors de l’analyse exploratoire, vous regarderez si les features extraites et utilisées en classification sont prometteuses en utilisant des méthodes de réduction de dimension pour visualiser le dataset en 2D. Cela vous permettra d’affiner votre intuition sur les différents traitements possibles, sans que cela ne se substitue à des mesures de performances rigoureuses.\n",
    "\n",
    "\n",
    "\n",
    "* Une approche s’appuyant sur l’état de l’art et l’utilisation de CNN (réseaux de neurones convolutionnels). Compte tenu de la taille et de la complexité du dataset, et de la puissance de calcul à votre disposition, il est très difficile d’obtenir de bonnes performances (pour ça, essayez MNIST). Aussi, est-il recommandé d’utiliser le transfer learning, c’est-à-dire utiliser un réseau déjà entraîné, et le modifier pour répondre à votre problème. Une première chose obligatoire est de ré-entraîner les dernières couches pour prédire les classes qui vous intéressent seulement. Il est également possible d’adapter la structure (supprimer certaines couches par exemple) ou de ré-entraîner le modèle avec un très faible learning rate pour ajuster les poids à votre problème (plus long) et optimiser les performances."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### New version of  `oP7_DataBreed` instance is updated and dumped\n",
    "\n",
    "When class `P7_DataBreed` is upaded, this lead to update methods and attributes.\n",
    "While attributes does not exists in old version of `P7_DataBreed`, this process allows \n",
    "to create an instance of latest version of `P7_DataBreed` class, update new attributes values and dump it.\n",
    "\n",
    "* Fist step : save \n",
    "    * Copy of `oP7_DataBreed` holds new methods.\n",
    "    * New attributes that does not exists into old version of `oP7_DataBreed` are masked into copy process\n",
    "* Second step : new attributes update\n",
    "    * Original instance of `oP7_DataBreed` is created; this instance hold new methods and new attributes.\n",
    "    * Saved instance of new version from `P7_DataBreed` is copied back into original instance.\n",
    "* Third step : backup of new instance \n",
    "    * New instance of `oP7_DataBreed` with new methods and updated attributes is dumped into a file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "if True :\n",
    "    oP7_DataBreed = P7_DataBreed.update_object_save(oP7_DataBreed, is_saved=True,is_new_attribute=True)\n",
    "else :\n",
    "    oP7_DataBreed = P7_DataBreed.P7_DataBreed('./data/Images')\n",
    "\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>0. PCA analysis</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.df_desc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_util_plot\n",
    "p3_util_plot.pca_all_plot(oP7_DataBreed.df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>1. Analysis with sampled dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.1. Loading the whole dataset</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import P7_DataBreed\n",
    "oP7_DataBreed=P7_DataBreed.P7_DataBreed('./data/EasyImages')\n",
    "oP7_DataBreed.load()\n",
    "oP7_DataBreed.std_size_build()\n",
    "oP7_DataBreed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.2. Sampling the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_dirbreed = ['n02107142-Doberman','n02115641-dingo','n02113978-Mexican_hairless']\n",
    "\n",
    "oP7_DataBreed.load(list_dirbreed=['n02107142-Doberman','n02115641-dingo','n02113978-Mexican_hairless'])\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.3. Building descriptors</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Filtered are assigned in regards with analysis from `P7_FilterExploration.ipynb` notebook"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed.list_processor_update(None, is_verbose=False)\n",
    "list_processor_id=[3,2,1]\n",
    "oP7_DataBreed.list_processor_update(list_processor_id, is_verbose=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed.std_size=(224,224)\n",
    "oP7_DataBreed.build_sift_desc(is_splitted=True)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>Building array of all Key points descriptors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "oP7_DataBreed.build_arr_desc()\n",
    "\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'> Hierarchical clustering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename ='./data/oP7_DataBreed.dump'\n",
    "oP7_DataBreed = p5_util.object_load(filename)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.cluster import AgglomerativeClustering\n",
    "import p5_util\n",
    "import P7_DataBreed\n",
    "is_hrc_clustering = True\n",
    "if is_hrc_clustering is True :\n",
    "    clustering='Hierarchical_clustering'\n",
    "\n",
    "    df_desc = oP7_DataBreed.df_desc\n",
    "    cluster_start = 1\n",
    "    cluster_end = oP7_DataBreed.sampling_breed_count\n",
    "\n",
    "    clustering=oP7_DataBreed.cluster_model_name\n",
    "    str_is_splitted = str(oP7_DataBreed.is_splitted)\n",
    "    filename='./data/dict_list_'+clustering+'_'+str(cluster_end)+'_splitted_'+str_is_splitted+'_clusters.dump'\n",
    "\n",
    "    dict_hyper_parameter={'covariance_type':['diag','spherical','full'], 'max_iter':200, 'verbose_interval':20}\n",
    "    #dict_hyper_parameter={'covariance_type':['full']}\n",
    "    #t_range_cluster = (cluster_start, cluster_end)\n",
    "    #dict_list_gmm_model = p5_util.gmm_hyper_parameter_cv(df_desc, t_range_cluster ,dict_hyper_parameter)\n",
    "\n",
    "    #p5_util.object_dump(dict_list_gmm_model,filename)\n",
    "    ward = AgglomerativeClustering(n_clusters=cluster_end, linkage='ward')#.fit(oP7_DataBreed.df_desc)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-----------------------------------------------------------------------------------\n",
    "# Dictionary of clusters model is updated\n",
    "#-----------------------------------------------------------------------------------\n",
    "oP7_DataBreed.dict_cluster_model = {'Hierarchical_clustering':ward}\n",
    "\n",
    "#if 'cluster' in df_desc.columns:\n",
    "#    del(df_desc['cluster'])\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#ward.labels_\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Data values (descriptors) are assigned to clusters\n",
    "#-----------------------------------------------------------------------------------\n",
    "pred_hclust = ward.fit_predict(df_desc.values)\n",
    "print(df_desc.shape)\n",
    "\n",
    "df_desc = p5_util.df_add_cluster(df_desc, pred_hclust)\n",
    "print(df_desc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Histogram for assignement is displayed\n",
    "#-----------------------------------------------------------------------------------\n",
    "p5_util_plot.plot_cluster_frequency(df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.4. GMM clustering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "\n",
    "filename = './data/oP7_DataBreed.dump'\n",
    "oP7_DataBreed = p5_util.object_load(filename)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "import P7_DataBreed\n",
    "\n",
    "df_desc = oP7_DataBreed.df_desc\n",
    "cluster_start = 1\n",
    "cluster_end = 3\n",
    "\n",
    "filename='./data/dict_list_gmm_model_'+str(cluster_end)+'_splited_clusters.dump'\n",
    "\n",
    "dict_hyper_parameter={'covariance_type':['diag','spherical','full']}\n",
    "dict_hyper_parameter={'covariance_type':['tied'], 'tol':[1e-4]}\n",
    "t_range_cluster = (cluster_start, cluster_end)\n",
    "dict_list_gmm_model = p5_util.gmm_hyper_parameter_cv(df_desc, t_range_cluster ,dict_hyper_parameter)\n",
    "\n",
    "p5_util.object_dump(dict_list_gmm_model,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/dict_list_gmm_model_'+str(cluster_end)+'_splited_clusters.dump'\n",
    "dict_list_gmm_model = p5_util.object_load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Plot AIC and BIC criteria"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "import p5_util_plot\n",
    "\n",
    "dict_list_gmm_model = p5_util.object_load(filename)\n",
    "\n",
    "p_figsize = (14,7)\n",
    "t_range_cluster = (cluster_start, cluster_end)\n",
    "breed_count = oP7_DataBreed._sampling_breed_count\n",
    "img_per_breed=oP7_DataBreed._sampling_image_per_breed_count\n",
    "p_title = 'GMM clustering 160K desc. / '+str(cluster_end)+' breeds'\n",
    "p5_util_plot.gmm_models_plot_AIC_BIC(df_desc, dict_list_gmm_model, t_range_cluster, p_figsize, p_title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_desc = oP7_DataBreed.df_desc\n",
    "df_desc.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compute and plot silhouette coefficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "df_desc = oP7_DataBreed.df_desc\n",
    "dict_dict_silhouette_score = p5_util.gmm_silhouette_compute(df_desc, dict_list_gmm_model)\n",
    "\n",
    "filename = './data/dict_dict_silhouette_score_'+str(cluster_end)+'_splitted_breeds.dump'\n",
    "p5_util.object_dump(dict_dict_silhouette_score,filename)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util_plot\n",
    "filename = './data/dict_dict_silhouette_score_'+str(cluster_end)+'_splitted_breeds.dump'\n",
    "dict_dict_silhouette_score = p5_util.object_load(filename)\n",
    "\n",
    "\n",
    "p_figsize=(21,14)\n",
    "areas_raws =1\n",
    "areas_colums =1\n",
    "p_title = \"GMM : silhouette\"\n",
    "p5_util_plot.gmm_models_plot_silhouette(df_desc, dict_dict_silhouette_score\\\n",
    ", p_figsize, p_title, areas_raws, areas_colums)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p_covariance_type = 'tied'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "import p5_util_plot\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Best GMM model is updated\n",
    "#-----------------------------------------------------------------------------------\n",
    "n_cluster = cluster_end\n",
    "list_gmm_model = dict_list_gmm_model[p_covariance_type]\n",
    "for gmm_model in list_gmm_model:\n",
    "    if n_cluster == gmm_model.n_components:\n",
    "        break\n",
    "gmm_model\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Dictionary of clusters model is updated\n",
    "#-----------------------------------------------------------------------------------\n",
    "oP7_DataBreed.dict_cluster_model = {'GMM':gmm_model}\n",
    "\n",
    "if 'cluster' in df_desc.columns:\n",
    "    del(df_desc['cluster'])\n",
    "    \n",
    "#-----------------------------------------------------------------------------------\n",
    "# Data values (descriptors) are assigned to clusters\n",
    "#-----------------------------------------------------------------------------------\n",
    "pred_gmm = gmm_model.predict(df_desc.values)\n",
    "print(df_desc.shape)\n",
    "\n",
    "df_desc = p5_util.df_add_cluster(df_desc, pred_gmm)\n",
    "print(df_desc.shape)\n",
    "\n",
    "#-----------------------------------------------------------------------------------\n",
    "# Histogram for assignement is displayed\n",
    "#-----------------------------------------------------------------------------------\n",
    "p5_util_plot.plot_cluster_frequency(df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.5. Building BOF</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### `GMM` model is used"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.cluster_model_name='GMM'\n",
    "#oP7_DataBreed.cluster_model_name='Hierarchical_clustering'\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building a bag of features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed._dict_breedname_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.build_ser_number_breedname()\n",
    "oP7_DataBreed._ser_breed_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.df_pil_image_kpdesc.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed.build_datakp_bof()\n",
    "oP7_DataBreed._ser_breed_number.keys()\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We check all BOF vectors are normalized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.df_bof.apply(lambda x: x.dot(x.T), axis=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.y_label.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>2. Supervized model </font>\n",
    "\n",
    "## <font color='blus'>2.1. Building model </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename = './data/oP7_DataBreed.dump'\n",
    "oP7_DataBreed = p5_util.object_load(filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.2. Model evaluation </font>\n",
    "\n",
    "Dataset dis splitted into train and test dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed.train_test_build(size_test=0.1)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### We make sure y_test and y_train vectors hold all classes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(oP7_DataBreed.y_test),np.unique(oP7_DataBreed.y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>3.2.1. Data model benchmark with supervized algorithm </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "is_dumped = False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    dict_cls_score = p5_util.object_load(filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    dict_classifier = p5_util.object_load(filename)\n",
    "else :\n",
    "    dict_cls_score = dict()\n",
    "    dict_classifier = dict()\n",
    "    is_dumped = True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Evaluation with hyper-parameter `multi_class='multinomial'`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import p5_util\n",
    "import p6_util\n",
    "import P7_DataBreed\n",
    "\n",
    "dict_param_grid = {\n",
    "    #'estimator__C': [ 1.e-3, 5e-3, 1e-2, 5.e-2, 1.e-1, 0.5, 1., 1.5], # Best classifier: 1.e-1, accuracy=0.41\n",
    "    #'estimator__C': [ 1.e-1, 0.5, 1., 1.5], # Best classifier: 0.1, accuracy=0.41\n",
    "    'estimator__C': [1e-6, 1e-5, 1.e-4, 1.e-3, 1.e-2, ], # Best classifier: 0.1, accuracy=0.41\n",
    "    'estimator__solver':['newton-cg', 'lbfgs' ,'sag'],\n",
    "    'estimator__penalty': ['l2',],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "cls_name = 'L.R. + multinomial'\n",
    "\n",
    "dict_cls_score = dict()\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "classifier = LogisticRegression(multi_class='multinomial',solver='newton-cg')\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "classifier  = gscv_classifier.best_estimator_\n",
    "best_score_ = gscv_classifier.best_score_\n",
    "\n",
    "dict_classifier[cls_name]=classifier\n",
    "dict_cls_score[cls_name] = best_score_\n",
    "\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Evaluation of Logictic regression with hyper-parameter `multi_class='ovr'`</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "import p5_util\n",
    "import p6_util\n",
    "import P7_DataBreed\n",
    "\n",
    "dict_param_grid = {\n",
    "    #'estimator__C': [ 1.e-1, 0.5, 1., 1.5], # Best classifier: 1.5, accuracy=0.27\n",
    "    #'estimator__C': [ 1.5, 2.0, 2.5], # Best classifier: 2.5, accuracy>0.27\n",
    "    #'estimator__C': [2.5, 5.0, 10., ], # Best classifier: 10.0 , accuracy=0.28\n",
    "    #'estimator__C': [10., 50., 100., ], # Best classifier: 100.0 , accuracy=0.29\n",
    "    'estimator__C': [140,150,200,300,500,1000], # Best classifier: 90.0 , accuracy=0.287\n",
    "    'estimator__solver':['newton-cg', 'lbfgs' ,'sag','liblinear'],\n",
    "    #'estimator__solver':[ 'saga','liblinear'],\n",
    "    'estimator__penalty': ['l2'],\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "cls_name = 'L.R. + ovr'\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "classifier = LogisticRegression(multi_class='ovr')\n",
    "\n",
    "print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=False)\n",
    "\n",
    "classifier  = gscv_classifier.best_estimator_\n",
    "best_score_ = gscv_classifier.best_score_\n",
    "\n",
    "dict_classifier[cls_name]=classifier\n",
    "dict_cls_score[cls_name] = best_score_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Evaluation of Bernoulli NB </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "import p6_util\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "\n",
    "if False :\n",
    "    scaler = StandardScaler()\n",
    "    scaler.fit(X_train)  \n",
    "    X_train = scaler.transform(X_train)\n",
    "    X_test = scaler.transform(X_test) \n",
    "\n",
    "classifier = BernoulliNB()\n",
    "cls_name = 'Bernoulli NB'\n",
    "\n",
    "dict_param_grid = {\n",
    "    'estimator__alpha': [ 1.e-4, 5.e-4, 1.e-3, 5.e-3, 1.e-2, 5.e-2, 1.e-1], # Best result : alfa=1E-4\n",
    "    #'estimator__alpha': [ 1.e-4, ], #\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "dict_cls_score\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Evaluation of Multinomial NB</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "\n",
    "cls_name = 'Multinomial NB'\n",
    "classifier = MultinomialNB()\n",
    "dict_param_grid = {\n",
    "    #'estimator__alpha': [ 1.e-3, 5.e-2, 1.e-1, 5.e-1, 1.], #1.e-3 : Accuracy 0.0\n",
    "    'estimator__alpha': [ 1.e-5, 1.e-4, 1.e-3,], #1.e-3 : Accuracy 0.0\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Evaluation of Gaussian NB</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import GaussianNB\n",
    "from scipy import sparse\n",
    "\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "\n",
    "cls_name = 'Gaussian NB'\n",
    "classifier = GaussianNB()\n",
    "\n",
    "dict_param_grid = dict()\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Linear SVC</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.svm import LinearSVC\n",
    "\n",
    "nb_estimators=100\n",
    "cls_name = 'Linear SVC'\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "\n",
    "dict_param_grid = {\n",
    "        #'estimator__C': [ 1e-1,5e-1,1.,0.5,10], # 10 / 0.282%\n",
    "        #'estimator__C': [ 10,20,30], # 30 / 0.283%\n",
    "        'estimator__C': [ 30, 50,100,200], # 100 / 0.283%\n",
    "        'n_jobs': [-1]\n",
    "}\n",
    "classifier = LinearSVC(multi_class='ovr')\n",
    "\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Random Forest</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "cls_name = 'Random Forest'\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "dict_param_grid = {\n",
    "    #'estimator__n_estimators': [ 100, 200, 300,], # 100, accuracy=0.295\n",
    "    #'estimator__n_estimators': [ 10,50,90,100,110], # 10, accuracy=0.297\n",
    "    'estimator__n_estimators': [ 5,9,10,11,15], # 10, accuracy=0.297\n",
    "}\n",
    "classifier = RandomForestClassifier()\n",
    "\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Kernel Ridge Classfier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import RidgeClassifier\n",
    "\n",
    "cls_name = 'Kernel Ridge'\n",
    "\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test  = oP7_DataBreed.X_test\n",
    "y_train = oP7_DataBreed.y_train\n",
    "y_test  = oP7_DataBreed.y_test\n",
    "dict_param_grid = {\n",
    "    'estimator__alpha': [ 0.1,1.,10.],# 0.1 / 0.281%\n",
    "    'n_jobs': [-1]\n",
    "}\n",
    "cls_name='KR Classifier'\n",
    "classifier = RidgeClassifier()\n",
    "\n",
    "y_pred, gscv_classifier = p6_util.p6_gscv_best_classifier(dict_param_grid, classifier, X_train, y_train\\\n",
    "                              , X_test,y_test,cv=3, iid=True)\n",
    "\n",
    "dict_cls_score[cls_name] = gscv_classifier.best_score_\n",
    "dict_classifier[cls_name]=gscv_classifier.best_estimator_\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "    filename = './data/best_dict_classifier.dump'\n",
    "    p5_util.object_dump(dict_classifier,filename)\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'>Benchmark results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import p5_util\n",
    "import p6_util_plot\n",
    "\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    dict_cls_score = p5_util.object_load(filename)\n",
    "else :\n",
    "    pass\n",
    "\n",
    "dict_benchmark_result = dict_cls_score.copy()\n",
    "\n",
    "df_result = pd.DataFrame.from_dict( dict_benchmark_result, orient='index')\n",
    "df_result.reset_index(inplace=True)\n",
    "df_result.rename(columns={'index':'Classifier',0:'Score'}, inplace=True)\n",
    "df_result\n",
    "nb_images = oP7_DataBreed._sampling_breed_count#*oP7_DataBreed._sampling_image_per_breed_count\n",
    "\n",
    "title = \"Image Classifiers accuracy / GMM clustering / \"+str(nb_images)+\" images\"\n",
    "p6_util_plot.ser_item_occurency_plot(df_result.Classifier, df_result.Score*100, item_count=None, title=title,\\\n",
    "                                    p_reverse=False)\n",
    "\n",
    "#### Classifier API\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.4. Building descriptors on a single splitted image</font>"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import cv2\n",
    "\n",
    "import p3_util\n",
    "import p3_util_plot\n",
    "\n",
    "import P7_DataBreed\n",
    "import p7_util\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def image_explore(self,breed_name, image_name, is_show) :\n",
    "    oP7_DataBreed_single = P7_DataBreed.P7_DataBreed()\n",
    "    oP7_DataBreed_single._dict_breed_sample=self._dict_breed_sample.copy()\n",
    "    oP7_DataBreed_single.show(is_show=is_show)\n",
    "    list_restricted_image = [(breedname,[image_name])]\n",
    "\n",
    "    oP7_DataBreed_single.list_restricted_image = list_restricted_image\n",
    "    oP7_DataBreed_single.show(is_show=is_show)\n",
    "    \n",
    "    \n",
    "    oP7_DataBreed_single.build_sift_desc(is_splitted=True)\n",
    "\n",
    "    oP7_DataBreed_single.show(is_show=is_show)\n",
    "    p7_util.p7_image_pil_show(oP7_DataBreed_single.dict_split_pil_image\\\n",
    "                              ,std_image_size=None, is_title=False)\n",
    "    return oP7_DataBreed_single\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def plot_kpdesc_image(self) :\n",
    "    '''\n",
    "        Input : None\n",
    "            \n",
    "        Output : \n",
    "            * list_breed_kpdesc : list of tuples structured as following :\n",
    "            (kp,descriptor), for each raw of splitted image.\n",
    "            * dict_breed_kpdesc_image : dictionary structures as following :\n",
    "            {breed: list_of_cv2.drawKeypoints}, for each raw of splitted image.\n",
    "    '''\n",
    "\n",
    "    raw_new = 0\n",
    "    list_kpdesc = list()\n",
    "    list_image_pil = list()\n",
    "\n",
    "    raw=0\n",
    "    col=0\n",
    "    breedname = self.df_pil_image_kpdesc.loc[(raw,col)][1]\n",
    "    for (raw,col) in self.df_pil_image_kpdesc.index :\n",
    "        desc = self.df_pil_image_kpdesc.loc[(raw,col)][0]\n",
    "        kp = self.df_pil_image_kpdesc.loc[(raw,col)][2]\n",
    "        pil_image = self.df_pil_image_kpdesc.loc[(raw,col)][4]\n",
    "        list_kpdesc.append((kp, desc))\n",
    "        list_image_pil.append(pil_image)\n",
    "    \n",
    "    dict_pil_image_   = {breedname:list_image_pil}\n",
    "    dict_breed_kpdesc = {breedname:list_kpdesc}        \n",
    "\n",
    "\n",
    "    dict_breed_kpdesc_image = dict()\n",
    "    dict_breed_kp_image = dict()\n",
    "    count=0\n",
    "    for (breed, list_breed_kpdesc)\\\n",
    "    , list_image_pil in zip(dict_breed_kpdesc.items(), dict_pil_image_.values()):\n",
    "        count +=1\n",
    "        dict_breed_kpdesc_image[breed] \\\n",
    "        = [cv2.drawKeypoints(np.array(image_pil), kp, np.array(image_pil)) \\\n",
    "            for ((kp, desc),image_pil) in zip(list_breed_kpdesc,list_image_pil)]\n",
    "\n",
    "    raw = self._split_ratio[0]\n",
    "    col = self._split_ratio[1]\n",
    "\n",
    "    breedname = list(dict_breed_kpdesc_image.keys())[0]\n",
    "\n",
    "    arr_= np.array(dict_breed_kpdesc_image[breedname])\n",
    "\n",
    "    dict_breed_kpdesc_image_raw = dict()\n",
    "    col_start = 0\n",
    "    for i_raw in range(0,raw) :\n",
    "        col_end = col_start+col\n",
    "        dict_breed_kpdesc_image_raw.update({i_raw:arr_[col_start:col_end,::,::,::]})\n",
    "        col_start =col_end\n",
    "\n",
    "\n",
    "    p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                              ,size_x=10,std_image_size=None,is_title=False)\n",
    "\n",
    "    return list_breed_kpdesc, dict_breed_kpdesc_image_raw\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def plot_filtered_kpdesc_image(list_breed_kpdesc, dict_breed_kpdesc_image_raw) :\n",
    "    '''Plot a splitted image that has been filtered based on KP distribution\n",
    "    in each splitted image.\n",
    "    \n",
    "    Input :\n",
    "        * list_breed_kpdesc : list of tuples; tuples are structured as following :\n",
    "            (kp_array, descriptors)\n",
    "        * dict_breed_kpdesc_image_raw : dictionary \n",
    "    '''\n",
    "\n",
    "    #---------------------------------------------------------------------------\n",
    "    # Building KP occurancies for each splitted image \n",
    "    #---------------------------------------------------------------------------\n",
    "    dict_kp_occurency = dict()\n",
    "    range_list = range(0,len(list_breed_kpdesc))\n",
    "\n",
    "    for i_raw, tuple_kp_image in zip(range_list, list_breed_kpdesc) :\n",
    "        dict_kp_occurency[i_raw] = len(tuple_kp_image[0])\n",
    "            \n",
    "    ser = pd.Series(dict_kp_occurency)\n",
    "    df_kp = pd.DataFrame([ser]).T.rename(columns={0:'count'})\n",
    "\n",
    "    p3_util_plot.df_boxplot_display(df_kp, 'count')\n",
    "\n",
    "    q1,q3,zmin,zmax = p3_util.df_boxplot_limits(df_kp , 'count')\n",
    "    print(\"Q1   = \"+str(q1))\n",
    "    print(\"Q3   = \"+str(q3))\n",
    "    print(\"Zmin = \"+str(zmin))\n",
    "    print(\"Zmax = \"+str(zmax))\n",
    "    \n",
    "    #---------------------------------------------------------------------------\n",
    "    # Filtering is applied\n",
    "    #---------------------------------------------------------------------------\n",
    "    df_kp_filtered = df_kp[df_kp['count']<int(q3)]\n",
    "    df_kp_filtered = df_kp_filtered[df_kp_filtered['count']>int(q1)]\n",
    "\n",
    "    list_filtered_index = list(df_kp_filtered.index)\n",
    "    index=0\n",
    "    for i_raw in range(0,raw):\n",
    "        col = dict_breed_kpdesc_image_raw[i_raw].shape[0]\n",
    "        \n",
    "        for i_col in range(0,col):\n",
    "            if index in list_filtered_index :\n",
    "                pass\n",
    "            else :\n",
    "                # Image index out of filter is erased \n",
    "                dict_breed_kpdesc_image_raw[i_raw][i_col] =np.zeros((50,50,3))\n",
    "            index += 1\n",
    "    \n",
    "    p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                              ,size_x=10,std_image_size=None,is_title=False)            \n",
    "#-------------------------------------------------------------------------------\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_name_id_unique\n",
    "name_id_unique = 'n02113799_3278'\n",
    "df = df_pil_image_kpdesc[df_pil_image_kpdesc.image_id==name_id_unique]\n",
    "for (raw, col), list_kp in df.kp.items():\n",
    "    print(raw,col)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_result.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "df_kp_filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "0 in df.index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(inplace=True)\n",
    "df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An object that aims to hold a single image is built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "oP7_DataBreed_single = P7_DataBreed.P7_DataBreed()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image structures are copied into `oP7_DataBreed_single` object"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_single._dict_breed_sample=oP7_DataBreed._dict_breed_sample.copy()\n",
    "oP7_DataBreed_single.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Images and breeds is shown \n",
    "\n",
    "This aims to select an image among list provided by a breed.\n",
    "\n",
    "List of breeds is displayed in a human readable manner along with directories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.show_breed_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "#### A breed name is picked from list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed._dict_breed_sample.keys()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Sample is restricted to a assigned list of image with a single element\n",
    "\n",
    "This allows to apply building descriptors methods for a single image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breedname  = 'Doberman'\n",
    "image_name = 'n02107142_16917.jpg'\n",
    "#list_restricted_image = [(breedname,image_name),('Saint_Bernard','n02109525_3360.jpg')]\n",
    "list_restricted_image = [(breedname,[image_name])]\n",
    "\n",
    "oP7_DataBreed_single.list_restricted_image = list_restricted_image\n",
    "oP7_DataBreed_single.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Image from object is splitted and KP are computed for each image part"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_single.build_sift_desc(is_splitted=True)\n",
    "\n",
    "oP7_DataBreed_single.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_single._df_pil_image_kpdesc.loc[(1,0)].split_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitted image below aims to be displayed with KP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p7_util\n",
    "#p7_util.p7_image_pil_show(dict_split_pil_image,std_image_size=(500,375), is_title=False)\n",
    "p7_util.p7_image_pil_show(oP7_DataBreed_single.dict_split_pil_image,std_image_size=None, is_title=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Building dictionaries for drawing invariant Key points for each splitted image\n",
    "\n",
    "`dict_breed_kpdesc_image` is structured as following : `{breedname:list_of_arrays}`\n",
    "\n",
    "where :\n",
    "\n",
    " * `list_of_arrays` is the list of array issued from `cv2.drawKeypoints()`\n",
    " \n",
    " The number of arrays is fixed by count of $raw\\times col$ where :\n",
    " * $raw$ is the number of raws issued from splitted image\n",
    " * $col$ is the number of columns issued from splitted image\n",
    " \n",
    "$cv2$ function is used to match key points along with images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = oP7_DataBreed_single\n",
    "\n",
    "\n",
    "import cv2\n",
    "\n",
    "raw_new = 0\n",
    "list_kpdesc = list()\n",
    "list_image_pil = list()\n",
    "\n",
    "raw=0\n",
    "col=0\n",
    "breedname = self.df_pil_image_kpdesc.loc[(raw,col)][1]\n",
    "for (raw,col) in self.df_pil_image_kpdesc.index :\n",
    "    desc = self.df_pil_image_kpdesc.loc[(raw,col)][0]\n",
    "    kp = self.df_pil_image_kpdesc.loc[(raw,col)][2]\n",
    "    pil_image = self.df_pil_image_kpdesc.loc[(raw,col)][4]\n",
    "    list_kpdesc.append((kp, desc))\n",
    "    list_image_pil.append(pil_image)\n",
    "    \n",
    "dict_pil_image_   = {breedname:list_image_pil}\n",
    "dict_breed_kpdesc = {breedname:list_kpdesc}        \n",
    "\n",
    "\n",
    "dict_breed_kpdesc_image = dict()\n",
    "dict_breed_kp_image = dict()\n",
    "count=0\n",
    "for (breed, list_breed_kpdesc), list_image_pil in zip(dict_breed_kpdesc.items(), dict_pil_image_.values()):\n",
    "    count +=1\n",
    "    dict_breed_kpdesc_image[breed] = [cv2.drawKeypoints(np.array(image_pil), kp, np.array(image_pil)) \\\n",
    "                             for ((kp, desc),image_pil) in zip(list_breed_kpdesc,list_image_pil)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Key points are drawned along with splitted images\n",
    "\n",
    "Dictionary hold a single key, the breed name.\n",
    "\n",
    "Flatten array in dictionary, containing KP to be displayed is splitted as $raw$ raws and $col$ columns. \n",
    "\n",
    "Result is stored into `arr_`variable.\n",
    "\n",
    "Processing during SIFT descriptors building has lead to truncate each image as a square. Then the number of raws is equal to the number of columns.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "self = oP7_DataBreed_single\n",
    "raw = self._split_ratio[0]\n",
    "col = self._split_ratio[1]\n",
    "\n",
    "breedname = list(dict_breed_kpdesc_image.keys())[0]\n",
    "\n",
    "arr_= np.array(dict_breed_kpdesc_image[breedname])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "`dict_breed_kpdesc_image_raw` will feed `p7_util.p7_image_pil_show` function.\n",
    "\n",
    "It is structured as following : `{raw:list_col_image}` where :\n",
    "* `list_col_image` is the column of images for `raw`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p7_util\n",
    "\n",
    "dict_breed_kpdesc_image_raw = dict()\n",
    "col_start = 0\n",
    "for i_raw in range(0,raw) :\n",
    "    col_end = col_start+col\n",
    "    dict_breed_kpdesc_image_raw.update({i_raw:arr_[col_start:col_end,::,::,::]})\n",
    "    col_start =col_end\n",
    "\n",
    "\n",
    "p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                          ,size_x=10,std_image_size=None,is_title=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Heuristic for KP filtering\n",
    "\n",
    "Image above shows that some areas with a great density of KP that are not focused \n",
    "on targeted object (dog). These KP may be regarded as noise considering expected information to be retrieved from KP focused on targeted object.\n",
    "\n",
    "\n",
    "Idea is to filter these areas based on KP density (number of KP per splitted images).\n",
    "\n",
    "Threashold min and max values are defined from KP distribution per splitted image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### For each splitted image, KP occurencies is computed\n",
    "\n",
    "`list_breed_kpdesc` contains KP for each split image.\n",
    "\n",
    "It is a flatten array. KP occurency is computed and stored into the dataframe `df_kp`.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_kp_occurency = dict()\n",
    "for i_raw in range(0,len(list_breed_kpdesc)) :\n",
    "    tuple_kp_image = list_breed_kpdesc[i_raw]\n",
    "    dict_kp_occurency[i_raw] = len(tuple_kp_image[0])\n",
    "\n",
    "ser = pd.Series(dict_kp_occurency)\n",
    "df_kp = pd.DataFrame([ser]).T.rename(columns={0:'count'})\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Threasholds are computed in order to filter splitted images.\n",
    "\n",
    "Dataframe `df_kp` is used to compute threashold and to build filter from this threashold used to keep images."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_util\n",
    "import p3_util_plot\n",
    "\n",
    "\n",
    "p3_util_plot.df_boxplot_display(df_kp, 'count')\n",
    "\n",
    "q1,q3,zmin,zmax = p3_util.df_boxplot_limits(df_kp , 'count')\n",
    "print(\"Q1   = \"+str(q1))\n",
    "print(\"Q3   = \"+str(q3))\n",
    "print(\"Zmin = \"+str(zmin))\n",
    "print(\"Zmax = \"+str(zmax))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_kp_filtered = df_kp[df_kp['count']<int(q3)]\n",
    "df_kp_filtered = df_kp_filtered[df_kp_filtered['count']>int(q1)]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Splitted images with are filtered against `list_index_filtered`"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "dict_breed_kpdesc_image_raw_save = dict_breed_kpdesc_image_raw.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dict_breed_kpdesc_image_raw = dict_breed_kpdesc_image_raw_save.copy()\n",
    "list_filtered_index = list(df_kp_filtered.index)\n",
    "index=0\n",
    "for i_row in range(0,row):\n",
    "    col = dict_breed_kpdesc_image_raw[i_row].shape[0]\n",
    "    #arr_ = np.zeros((4,50,50,3))\n",
    "    for i_col in range(0,col):\n",
    "        if index in list_filtered_index :\n",
    "            pass\n",
    "        else :\n",
    "            # Image index out of filter is erased \n",
    "            dict_breed_kpdesc_image_raw[i_row][i_col] =np.zeros((50,50,3))\n",
    "        index += 1\n",
    "            "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p7_util\n",
    "if True :\n",
    "    p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                              ,size_x=10,std_image_size=None,is_title=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Applying KP filtering process on another image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An object that aims to hold a single image is built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import p3_util\n",
    "import p3_util_plot\n",
    "\n",
    "\n",
    "import P7_DataBreed\n",
    "import p7_util\n",
    "\n",
    "oP7_DataBreed_single = P7_DataBreed.P7_DataBreed()\n",
    "\n",
    "oP7_DataBreed_single._dict_breed_sample=oP7_DataBreed._dict_breed_sample.copy()\n",
    "\n",
    "\n",
    "breedname  = 'Doberman'\n",
    "image_name = 'n02107142_7300.jpg'\n",
    "image_name = 'n02107142_7237.jpg'\n",
    "image_name = 'n02107142_278.jpg'\n",
    "image_name = 'n02107142_15936.jpg'\n",
    "image_name = 'n02107142_12191.jpg'\n",
    "image_name = 'n02107142_16917.jpg'\n",
    "\n",
    "list_restricted_image = [(breedname,[image_name])]\n",
    "\n",
    "oP7_DataBreed_single.list_restricted_image = list_restricted_image\n",
    "\n",
    "oP7_DataBreed_single.build_sift_desc(is_splitted=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p7_util.p7_image_pil_show(oP7_DataBreed_single.dict_split_pil_image,std_image_size=(500,375), is_title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(dict_pil_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_kp_count = dict()\n",
    "list_image_pil = list()\n",
    "dict_pil_image_ = dict()\n",
    "list_kpdesc = list()\n",
    "\n",
    "dict_pil_image = oP7_DataBreed_single.dict_split_pil_image\n",
    "print(len(dict_pil_image))\n",
    "\n",
    "for list_pil_image in dict_pil_image.values():\n",
    "    for pil_image in list_pil_image :\n",
    "        list_image_pil.append(pil_image)\n",
    "        kp, desc = P7_DataBreed.get_image_kpdesc(pil_image)\n",
    "        list_kpdesc.append((kp, desc))\n",
    "    \n",
    "dict_pil_image_={breedname:list_image_pil}\n",
    "dict_breed_kpdesc={breedname:list_kpdesc}\n",
    "\n",
    "\n",
    "dict_breed_kpdesc_image = dict()\n",
    "dict_breed_kp_image = dict()\n",
    "count=0\n",
    "for (breed, list_breed_kpdesc), list_image_pil in zip(dict_breed_kpdesc.items(), dict_pil_image_.values()):\n",
    "    count +=1\n",
    "    dict_breed_kpdesc_image[breed] = [cv2.drawKeypoints(np.array(image_pil), kp, np.array(image_pil)) \\\n",
    "                             for ((kp, desc),image_pil) in zip(list_breed_kpdesc,list_image_pil)]\n",
    "\n",
    "arr_= np.array(dict_breed_kpdesc_image[breedname])\n",
    "raw = int(np.sqrt(arr_.shape[0]))\n",
    "col = raw\n",
    "\n",
    "#arr_= np.array(dict_breed_kpdesc_image[breedname])\n",
    "dict_breed_kpdesc_image_raw = dict()\n",
    "col_start = 0\n",
    "for i_raw in range(0,raw) :\n",
    "    col_end = col_start+col\n",
    "    dict_breed_kpdesc_image_raw.update({i_raw:arr_[col_start:col_end,::,::,::]})\n",
    "    col_start =col_end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                          ,size_x=10,std_image_size=None,is_title=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_kp_occurency = dict()\n",
    "for i_raw in range(0,len(list_breed_kpdesc)) :\n",
    "    tuple_kp_image = list_breed_kpdesc[i_raw]\n",
    "    dict_kp_occurency[i_raw] = len(tuple_kp_image[0])\n",
    "\n",
    "ser = pd.Series(dict_kp_occurency)\n",
    "df_kp = pd.DataFrame([ser]).T.rename(columns={0:'count'})\n",
    "#df_kp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "p3_util_plot.df_boxplot_display(df_kp, 'count')\n",
    "\n",
    "q1,q3,zmin,zmax = p3_util.df_boxplot_limits(df_kp , 'count')\n",
    "print(\"Q1   = \"+str(q1))\n",
    "print(\"Q3   = \"+str(q3))\n",
    "print(\"Zmin = \"+str(zmin))\n",
    "print(\"Zmax = \"+str(zmax))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "kp_min=zmin\n",
    "kp_max=q3\n",
    "\n",
    "df_kp_filtered = df_kp[df_kp['count']<int(kp_max)]\n",
    "df_kp_filtered = df_kp_filtered[df_kp_filtered['count']>int(kp_min)]\n",
    "if False :\n",
    "    dict_breed_kpdesc_image_raw_save = dict_breed_kpdesc_image_raw.copy()\n",
    "    dict_breed_kpdesc_image_raw = dict_breed_kpdesc_image_raw_save.copy()\n",
    "list_filtered_index = list(df_kp_filtered.index)\n",
    "\n",
    "index=0\n",
    "for i_raw in range(0,raw):\n",
    "    col = dict_breed_kpdesc_image_raw[i_raw].shape[0]\n",
    "    #arr_ = np.zeros((4,50,50,3))\n",
    "    for i_col in range(0,col):\n",
    "        if index in list_filtered_index :\n",
    "            pass\n",
    "        else :\n",
    "            # Image index out of filter is erased \n",
    "            dict_breed_kpdesc_image_raw[i_raw][i_col] =np.zeros((50,50,3))\n",
    "        index += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "            \n",
    "p7_util.p7_image_pil_show(dict_breed_kpdesc_image_raw\\\n",
    "                          ,size_x=10,std_image_size=None,is_title=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>Applying KP filtering process on a breed</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_name  = 'Doberman'\n",
    "image_name = 'n02107142_16917.jpg'\n",
    "\n",
    "oP7_DataBreed_explorer = image_explore(oP7_DataBreed,breed_name, image_name, False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* `list_kpdesc` contains tuple of (KP,descriptors) for all splitted image. Flatten image is represented as a flatten array.\n",
    "\n",
    "* `dict_breed_kpdesc_image_raw` "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_kpdesc, dict_breed_kpdesc_image_raw = plot_kpdesc_image(oP7_DataBreed_explorer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "plot_filtered_kpdesc_image(list_kpdesc, dict_breed_kpdesc_image_raw)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>Applying KP filtering process on all images</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "oP7_DataBreed=P7_DataBreed.P7_DataBreed('./data/EasyImages')\n",
    "oP7_DataBreed.load()\n",
    "oP7_DataBreed.std_size_build()\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>Sampling the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breed_count=10\n",
    "image_per_breed_count=10\n",
    "oP7_DataBreed.std_size=None\n",
    "\n",
    "oP7_DataBreed.sampling(breed_count, image_per_breed_count)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images from object is splitted and KP are computed for each splitted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.build_sift_desc(is_splitted=True)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##### Rows are filtered considering KP density over splitted image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.kp_filter()\n",
    "\n",
    "oP7_DataBreed.build_arr_desc()\n",
    "\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>2. Analysis with images filtered by hand</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.1. Loading the whole dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "oP7_DataBreed=P7_DataBreed.P7_DataBreed('./data/EasyImages')\n",
    "oP7_DataBreed.load()\n",
    "oP7_DataBreed.std_size_build()\n",
    "\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.2. Sampling the dataset</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "breed_count=10\n",
    "image_per_breed_count=20\n",
    "oP7_DataBreed.std_size=(200,200)\n",
    "\n",
    "oP7_DataBreed.sampling(breed_count, image_per_breed_count)\n",
    "\n",
    "oP7_DataBreed.build_sift_desc(is_splitted=True)\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.3. Building array of all Key points descriptors</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "oP7_DataBreed.build_arr_desc()\n",
    "\n",
    "oP7_DataBreed.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = './data/oP7_DataBreed.dump'\n",
    "p5_util.object_dump(oP7_DataBreed,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.5. DBSCAN clustering</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.X_train.shape,oP7_DataBreed.X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_util_plot\n",
    "X_train = oP7_DataBreed.X_train\n",
    "X_test = oP7_DataBreed.X_test\n",
    "labels_trained, labels_predicted \\\n",
    "= p3_util_plot.clustering_dbscan_plot_and_metrics(X_train, X_test,parameter_eps=3,parameter_min_samples=10) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.6. t-SNE</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "\n",
    "df_desc = oP7_DataBreed.df_desc\n",
    "dict_tsne_result = p5_util.tsne_2D_process_perplexity(df_desc)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>4. Estimator model evaluation</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename = './data/oP7_DataBreed_compress.dump'\n",
    "p5_util.object_compress_dump(oP7_DataBreed,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed_new = P7_DataBreed.P7_DataBreed('./data/EasyImages')\n",
    "filename = './data/best_dict_classifier.dump'\n",
    "oP7_DataBreed_new.dict_classifier_load(filename)\n",
    "\n",
    "oP7_DataBreed_new.dict_cluster_model = oP7_DataBreed.dict_cluster_model\n",
    "oP7_DataBreed_new._cluster_model_name='GMM'\n",
    "oP7_DataBreed_new.classifier_name = 'Bernoulli NB'\n",
    "oP7_DataBreed_new._ser_breed_number = oP7_DataBreed._ser_breed_number.copy()\n",
    "oP7_DataBreed_new.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### <font color='blus'> Show breeds names and images from breed that are not into images sample</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.show_breedname()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.show_image_name('standard_poodle', is_sample_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p7_util\n",
    "import P7_DataBreed\n",
    "\n",
    "dirbreed  = 'n02113799-standard_poodle'\n",
    "imagename = 'n02113799_895.jpg'\n",
    "\n",
    "print(oP7_DataBreed_new.predict(dirbreed,imagename))\n",
    "\n",
    "dict_pil_image = P7_DataBreed.process_breed_sample(oP7_DataBreed.dir_path+'/'+dirbreed, [imagename] , oP7_DataBreed.std_size)\n",
    "\n",
    "dict_pil_image_display = dict()\n",
    "dict_pil_image_display['Equalized'] = dict_pil_image['equalize'][0]\n",
    "p7_util.p7_image_pil_show(dict_pil_image_display,std_image_size=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirbreed  = 'n02107142-Doberman'\n",
    "\n",
    "imagename = 'n02107142_385.jpg'\n",
    "oP7_DataBreed_new.predict(dirbreed,imagename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_new._ser_breed_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirbreed = 'n02105162-malinois'\n",
    "imagename ='n02105162_3346.jpg'\n",
    "oP7_DataBreed_new.predict(dirbreed,imagename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagename = 'n02109525_13154.jpg'\n",
    "dirbreed = 'n02109525-Saint_Bernard'\n",
    "oP7_DataBreed_new.predict(dirbreed,imagename,top=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirbreed = 'n02116738-African_hunting_dog'\n",
    "imagename = 'n02116738_634.jpg'\n",
    "oP7_DataBreed_new.predict(dirbreed,imagename,top=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_new._ser_breed_number"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dirbreed = 'n02108089-boxer'\n",
    "\n",
    "dict_list_image = p7_util.p7_load_data(oP7_DataBreed.dir_path, dirbreed)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed._dict_breed_sample[dirbreed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_list_image[dirbreed]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "imagename = 'n02108089_12739.jpg'\n",
    "oP7_DataBreed_new.predict(dirbreed,imagename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed_new.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(oP7_DataBreed._dict_breedname_id)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed._dict_breed_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
