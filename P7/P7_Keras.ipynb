{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import P7_DataBreed\n",
    "import p5_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from  sklearn import model_selection\n",
    "import numpy as np\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def arr_X_y_build(X,y):\n",
    "    list_X = [np.array(x) for x in X]\n",
    "    list_y = [Y for Y in y]\n",
    "\n",
    "    weight  = list_X[0].shape[0]\n",
    "    height  = list_X[0].shape[1]\n",
    "    channel = list_X[0].shape[2]\n",
    "    \n",
    "    arr_X  = list_X[0].reshape((1, weight, height, channel))\n",
    "    \n",
    "\n",
    "    image_count = X.shape[0]\n",
    "    list_image_error = list()\n",
    "    for image_i in range(1,image_count) :\n",
    "        try :\n",
    "            arr_X\\\n",
    "            = np.append(arr_X,list_X[image_i].reshape((1, weight, height, channel)),axis=0)\n",
    "        except ValueError :\n",
    "            list_image_error.append(image_i)\n",
    "\n",
    "    arr_y = np.array(y)\n",
    "    return arr_X, arr_y\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def arr_X_train_test_build(X,y,test_size=0.2):\n",
    "    X_train, X_test, y_train,  y_test \\\n",
    "    = model_selection.train_test_split(X,y,test_size=test_size)\n",
    "\n",
    "    print(X_train.shape, y_train.shape, X_test.shape, y_test.shape)\n",
    "    print(\"Images for training...\")\n",
    "    arr_X_train, arr_y_train = arr_X_y_build(X_train, y_train)\n",
    "    print(\"Images for testing...\")\n",
    "    arr_X_test, arr_y_test = arr_X_y_build(X_test, y_test)\n",
    "    return arr_X_train, arr_X_test, arr_y_train, arr_y_test\n",
    "#-------------------------------------------------------------------------------"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename= './data/df_breed_image.dump'\n",
    "df = p5_util.object_load(filename)\n",
    "df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['image'] = df['image'].apply(lambda ser : ser.resize((200,200)))\n",
    "filename= './data/df_breed_image.dump'\n",
    "p5_util.object_dump(df ,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute following cell in order to update object version with no change in attributes**\n",
    "\n",
    "* A backup instance of object is created. This backup instance is empty.\n",
    "* If object instance is not defined then it is read from dmped file.\n",
    "* object instance is copied back into backup instance\n",
    "* Backup instance is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_attribute=None\n",
    "\n",
    "import p5_util\n",
    "import P7_DataBreed\n",
    "\n",
    "if new_attribute is None :\n",
    "    is_saved = True\n",
    "    filename='./data/oP7_DataBreed.dump'\n",
    "    oP7_DataBreed_save = P7_DataBreed.P7_DataBreed()\n",
    "    try: \n",
    "        oP7_DataBreed\n",
    "    except NameError:\n",
    "        print('*** INFO : oP7_DataBreed is not defined; loading...')\n",
    "        oP7_DataBreed = p5_util.object_load(filename)\n",
    "        is_saved = False\n",
    "    oP7_DataBreed_save.copy(oP7_DataBreed)\n",
    "    oP7_DataBreed = P7_DataBreed.P7_DataBreed()\n",
    "    oP7_DataBreed.copy(oP7_DataBreed_save)\n",
    "    del(oP7_DataBreed_save)\n",
    "    oP7_DataBreed.show()\n",
    "    is_saved=True\n",
    "    if is_saved is True:\n",
    "        print('*** INFO : oP7_DataBreed is saved')\n",
    "        p5_util.object_dump(oP7_DataBreed,filename)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Data-model**\n",
    "\n",
    "DataFrame with columns as images, breed names and labels is built.\n",
    "\n",
    "Labels are issued from encoding breed names. \n",
    "\n",
    "Labels are then used for training Keras network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oP7_DataBreed.df_build()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe is saved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "\n",
    "filename= './data/df_breed_image.dump'\n",
    "p5_util.object_dump(df,filename)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.shape, df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image truncated against image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pil_image = df['image']\n",
    "ser_label = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original image sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = ser_pil_image.iloc[0]\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resized image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "pil_image.resize((204,204))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated image as square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import P7_DataBreed\n",
    "square=(204,204)\n",
    "pil_image_truncated = P7_DataBreed.pil_square(ser_pil_image.iloc[0], square=square)\n",
    "print(np.array(pil_image_truncated).shape)\n",
    "#arr_keras_X = arr_keras_X.reshape(1,arr_keras_X.shape[0],arr_keras_X.shape[1],arr_keras_X.shape[2])\n",
    "pil_image_truncated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test sample, Keras compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "arr_keras_image_train, arr_keras_image_test, arr_label_train, arr_label_test \\\n",
    "= P7_DataBreed.p7_keras_X_train_test_build(ser_pil_image, ser_label, test_size=0.2, square=(204,204))\n",
    "\n",
    "arr_keras_image_train.shape, arr_keras_image_test.shape, arr_label_train.shape, arr_label_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "p5_util.object_dump((arr_keras_image_train, arr_keras_image_test, arr_label_train, arr_label_test),filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building Keras network"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dumped file for train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "(arr_X_train,arr_X_test, arr_y_train, arr_y_test) = p5_util.object_load(filename)\n",
    "print(arr_X_train.shape,arr_X_test.shape,arr_y_train.shape,arr_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building Keras layers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense\n",
    "\n",
    "my_VGG16 = Sequential()  # Création d'un réseau de neurones vide \n",
    "\n",
    "# Ajout de la première couche de convolution, suivie d'une couche ReLU\n",
    "w=arr_X_train.shape[1]\n",
    "h=arr_X_train.shape[2]\n",
    "c=arr_X_train.shape[3]\n",
    "print(w,h,c)\n",
    "my_VGG16.add(Conv2D(64, (3, 3), input_shape=(w, h, c), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "my_VGG16.add(Conv2D(64, (3, 3), padding='same', activation='relu'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la première couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))\n"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "\n",
    "my_VGG16.add(Flatten())  # Conversion des matrices 3D en vecteur 1D\n",
    "\n",
    "# Ajout de la première couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(7, activation='relu'))\n",
    "\n",
    "# Ajout de la deuxième couche fully-connected, suivie d'une couche ReLU\n",
    "my_VGG16.add(Dense(7, activation='relu'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Ajout de la dernière couche fully-connected qui permet de classifier\n",
    "my_VGG16.add(Flatten())  # Conversion des matrices 3D en vecteur 1D\n",
    "nb_labels = arr_y_train.shape[0]\n",
    "print(\"Number of labels for training process : \"+str(nb_labels))\n",
    "my_VGG16.add(Dense(nb_labels, activation='softmax'))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "#my_VGG16.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "my_VGG16.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#for X_train, y_train in zip(list_X_train, list_y_train):\n",
    "print(arr_X_train.shape)\n",
    "my_VGG16.fit(arr_X_train, arr_y_train)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "my_VGG16.get_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test for images classification**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_result = my_VGG16.predict(arr_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= './data/result_vgg16.dump'\n",
    "p5_util.object_dump(arr_result,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_result.shape,arr_y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.unique(arr_y_train).shape[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.where(arr_result>0.3)[0].shape,np.where(arr_result>0.3)[1].shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_result = my_VGG16.predict_classes(arr_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "arr_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
