{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import P7_DataBreed\n",
    "import p5_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from  sklearn import model_selection\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename= './data/df_breed_image.dump'\n",
    "if False :\n",
    "    df = p5_util.object_load(filename)\n",
    "    df.shape"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "df['image'] = df['image'].apply(lambda ser : ser.resize((200,200)))\n",
    "filename= './data/df_breed_image.dump'\n",
    "p5_util.object_dump(df ,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "if True :\n",
    "    oP7_DataBreed = p5_util.object_load('./data/oP7_DataBreed.dump')\n",
    "    oP7_DataBreed.show()\n",
    "    oP7_DataBreed.breed_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Build a sample dataset :\n",
    "\n",
    "Sampling is leaded by 2 parameters :\n",
    "* `breed_count` : number of breeds into the dataset\n",
    "* `image_per_breed_count` : for each breed, number of image into sample."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed=P7_DataBreed.P7_DataBreed('./data/Images')\n",
    "oP7_DataBreed.std_size=None\n",
    "oP7_DataBreed.is_squarred=False\n",
    "oP7_DataBreed.is_kp_filtered=False\n",
    "is_splitted=True\n",
    "oP7_DataBreed.split_ratio=(3,3)\n",
    "oP7_DataBreed.load()\n",
    "breed_count=3\n",
    "image_per_breed_count=100\n",
    "list_breed_sample=['n02107142-Doberman','n02115641-dingo','n02113978-Mexican_hairless']\n",
    "#list_breed_sample=['n02107142-Doberman']\n",
    "oP7_DataBreed.list_breed_sample = list_breed_sample\n",
    "oP7_DataBreed.sampling(breed_count, image_per_breed_count)\n",
    "\n",
    "oP7_DataBreed.show()\n",
    "oP7_DataBreed.show_breed_name()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Execute following cell in order to update object version with no change in attributes**\n",
    "\n",
    "* A backup instance of object is created. This backup instance is empty.\n",
    "* If object instance is not defined then it is read from dmped file.\n",
    "* object instance is copied back into backup instance\n",
    "* Backup instance is deleted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "if False :\n",
    "    oP7_DataBreed = P7_DataBreed.update_object_save(oP7_DataBreed, is_saved=False,is_new_attribute=True)\n",
    "    oP7_DataBreed.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Building Data-model**\n",
    "\n",
    "DataFrame with columns as images, breed names and labels is built.\n",
    "\n",
    "Labels are issued from encoding breed names. \n",
    "\n",
    "Labels are then used for training Keras network. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = oP7_DataBreed.df_build()\n",
    "df.label.unique(),df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dataframe is saved**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "\n",
    "filename= './data/df_breed_image.dump'\n",
    "p5_util.object_dump(df,filename)\n",
    "df.sample()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image truncated against image resize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ser_pil_image = df['image']\n",
    "ser_label = df['label']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Original image sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pil_image = ser_pil_image.iloc[0]\n",
    "print(pil_image.size)\n",
    "pil_image"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Resized image\n",
    "\n",
    "Resize does not lead to loss of information due to truncation.\n",
    "<br>\n",
    "Resizing allows to consume less resources into CNN network."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from PIL import Image\n",
    "pil_image_resize = pil_image.resize((224,224))\n",
    "pil_image_resize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Truncated image as square"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import P7_DataBreed\n",
    "if False :\n",
    "    square=(204,204)\n",
    "    pil_image_truncated = P7_DataBreed.pil_square(ser_pil_image.iloc[0], square=square)\n",
    "    print(np.array(pil_image_truncated).shape)\n",
    "    #arr_keras_X = arr_keras_X.reshape(1,arr_keras_X.shape[0],arr_keras_X.shape[1],arr_keras_X.shape[2])\n",
    "    pil_image_truncated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building train and test sample, Keras compliant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "square = None\n",
    "resize = (224,224)\n",
    "test_size=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "arr_keras_image_train, arr_keras_image_test, arr_label_train, arr_label_test \\\n",
    "= P7_DataBreed.p7_keras_X_train_test_build(ser_pil_image, ser_label, test_size=test_size, square=square, resize=resize)\n",
    "\n",
    "arr_keras_image_train.shape, arr_keras_image_test.shape, arr_label_train.shape, arr_label_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Dump train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "p5_util.object_dump((arr_keras_image_train, arr_keras_image_test, arr_label_train, arr_label_test),filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>1. Breeds classification using Keras MLP model</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.utils import to_categorical\n",
    "import p5_util\n",
    "\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "(X_train,X_test, y_train, y_test) = p5_util.object_load(filename)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "\n",
    "#### Data normalization\n",
    "X_train = X_train.astype('float32')\n",
    "X_test  = X_test.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "X_train /= 255\n",
    "X_test /= 255\n",
    "## Retrieve number of classes\n",
    "nClasses = len(np.unique(y_train))\n",
    "print(\"Number of classses= \"+str(nClasses))\n",
    "\n",
    "### One hot encoding of labels\n",
    "y_train_one_hot_enc = to_categorical(y_train)\n",
    "y_test_one_hot_enc = to_categorical(y_test)\n",
    "print()\n",
    "print(y_train_one_hot_enc.shape)\n",
    "print(y_test_one_hot_enc.shape)\n",
    "\n",
    "dimData = np.prod(X_train.shape[1:])\n",
    "print(dimData)\n",
    "\n",
    "X_train = X_train.reshape(X_train.shape[0], dimData)\n",
    "X_test  = X_test.reshape(X_test.shape[0], dimData)\n",
    "print(X_train.shape)\n",
    "print(X_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Building MLP network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense,Dropout\n",
    "from keras import optimizers\n",
    "\n",
    "mlp_model = Sequential()\n",
    "mlp_model.add(Dense(512, activation='relu', input_shape=(dimData,)))\n",
    "mlp_model.add(Dropout(0.5))\n",
    "\n",
    "mlp_model.add(Dense(512, activation='relu'))\n",
    "mlp_model.add(Dropout(0.5))\n",
    "\n",
    "#mlp_model.add(Dense(512, activation='relu'))\n",
    "#mlp_model.add(Dropout(0.5))\n",
    "\n",
    "mlp_model.add(Dense(nClasses, activation='softmax'))\n",
    "sgd = optimizers.SGD(lr=5.e-4)\n",
    "\n",
    "mlp_model.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "mlp_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Training model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "history = mlp_model.fit(X_train,\n",
    "                    y_train_one_hot_enc,\n",
    "                    epochs=50,\n",
    "                    batch_size=50,\n",
    "                    validation_data=(X_test,y_test_one_hot_enc))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Display results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "[test_loss, test_acc] = mlp_model.evaluate(X_test, y_test_one_hot_enc)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))\n",
    "\n",
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=1.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves ',fontsize=16)\n",
    " \n",
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>2. Breeds classification using CNN VGG16 network</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Read dumped file for train and test sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "(arr_X_train,arr_X_test, arr_y_train, arr_y_test) = p5_util.object_load(filename)\n",
    "print(arr_X_train.shape,arr_X_test.shape,arr_y_train.shape,arr_y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Building VGG16 Keras layers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st convolution layer is added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Flatten, Dense, Dropout\n",
    "\n",
    "VGG16Seq = Sequential()  # Création d'un réseau de neurones vide \n",
    "\n",
    "# Ajout de la première couche de convolution, suivie d'une couche ReLU\n",
    "w=arr_X_train.shape[1]\n",
    "h=arr_X_train.shape[2]\n",
    "c=arr_X_train.shape[3]\n",
    "print(w,h,c)\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), input_shape=(w, h, c), padding='same', activation='relu'))\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "VGG16Seq.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd convolution layer is added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "VGG16Seq.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3th convolution layer is added "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Ajout de la deuxième couche de convolution, suivie  d'une couche ReLU\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), padding='same', activation='relu'))\n",
    "VGG16Seq.add(Conv2D(64, (3, 3), activation='relu'))\n",
    "VGG16Seq.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Pooling layer is added "
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ajout de la première couche de pooling\n",
    "my_VGG16.add(MaxPooling2D(pool_size=(2,2), strides=(2,2)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nb_labels = arr_y_train.shape[0]\n",
    "print(\"Number of labels for training process : \"+str(nb_labels))\n",
    "VGG16Seq.add(Flatten())  # Conversion des matrices 3D en vecteur 1D"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 1st Dense layer is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16Seq.add(Dense(nb_labels, activation='relu'))\n",
    "VGG16Seq.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2nd Dense layer is added"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# Ajout de la deuxième couche fully-connected, suivie d'une couche ReLU\n",
    "VGG16Seq.add(Dense(nb_labels, activation='relu'))\n",
    "VGG16Seq.add(Dropout(0.5))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 3th Dense layer is added"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "# Ajout de la dernière couche fully-connected qui permet de classifier\n",
    "VGG16Seq.add(Dense(nb_labels, activation='softmax'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### VGG16 compilation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import optimizers\n",
    "sgd = optimizers.SGD(lr=1e-3, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "rmsprop = optimizers.RMSprop(lr=1e-4)\n",
    "\n",
    "#my_VGG16.compile(optimizer=sgd, loss='categorical_crossentropy', metrics=['accuracy'])\n",
    "#my_VGG16.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "VGG16Seq.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Keras Sequential model is dumped"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "p5_util.object_dump(VGG16Seq,'./data/VGG16Seq_sgd.dump')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "VGG16Seq.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading VGG166 Sequential model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import display, clear_output\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "import P7_DataBreed\n",
    "import p5_util\n",
    "\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload\n",
    "\n",
    "from  sklearn import model_selection\n",
    "import numpy as np\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "import p5_util\n",
    "if True:\n",
    "    VGG16Seq = p5_util.object_load('./data/VGG16Seq_sgd.dump')\n",
    "    VGG16Seq.summary()\n",
    "\n",
    "import p5_util\n",
    "import P7_DataBreed\n",
    "if False :\n",
    "    oP7_DataBreed = p5_util.object_load('./data/oP7_DataBreed.dump')\n",
    "    oP7_DataBreed.show()\n",
    "    oP7_DataBreed.breed_show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Test for images classification"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Data is loaded form dumped file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "(arr_X_train,arr_X_test, arr_y_train, arr_y_test) = p5_util.object_load(filename)\n",
    "print(arr_X_train.shape,arr_X_test.shape,arr_y_train.shape,arr_y_test.shape)\n",
    "\n",
    "#### Data normalization\n",
    "\n",
    "arr_X_train = arr_X_train.astype('float32')\n",
    "arr_X_test = arr_X_test.astype('float32')\n",
    "\n",
    "# Scale the data to lie between 0 to 1\n",
    "arr_X_train /= 255\n",
    "arr_X_test /= 255"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "print(arr_X_train.shape)\n",
    "history = VGG16Seq.fit(arr_X_train, arr_y_train, epochs=50, batch_size=90,verbose=1,validation_data=(arr_X_test, arr_y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[test_loss, test_acc] = VGG16Seq.evaluate(arr_X_test, arr_y_test)\n",
    "print(\"Evaluation result on Test Data : Loss = {}, accuracy = {}\".format(test_loss, test_acc))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Plot the Loss Curves\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=1.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves ',fontsize=16)\n",
    " \n",
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "is_score_dumped=True\n",
    "if is_score_dumped is True :\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    dict_cls_score = p5_util.object_load(filename)\n",
    "else:\n",
    "    dict_cls_score = dict()\n",
    "dict_classifier = dict()\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = VGG16Seq.predict(arr_X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename= './data/result_VGG16Seq.dump'\n",
    "p5_util.object_dump(y_pred,filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Measure of accuracy\n",
    "\n",
    "Result is stored into `arr_result` where :\n",
    "* rows : number of observations from test dataset\n",
    "* columns : probabibilty for each observation from train dataset.\n",
    "\n",
    "For each row from `arr_result`, greater probability value is searched for. \n",
    "<br>\n",
    "The result of search provides index of label into `list_index`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "filename= './data/result_vgg16.dump'\n",
    "p5_util.object_load(y_pred,filename)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "# List of indexes greater probabilities: greater values for each row from arr_result.\n",
    "list_index = [np.where(y_pred[i] == max(y_pred[i]))[0][0] for i in range(0, len(y_pred))]\n",
    "\n",
    "#print(arr_result)\n",
    "print(len(arr_y_train))\n",
    "print(list_index)\n",
    "list_result = [arr_y_train[list_index[i]][0] for i in range(0,len(list_index))]\n",
    "\n",
    "score_keras = len(set(list_result).intersection(arr_y_test.flatten()))/len(list(arr_y_test))\n",
    "print(\"*** INFO : Result accuracy = {0:1.1F}%\".format(score_keras*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "(loss, score_vgg16_seq) = VGG16Seq.evaluate(arr_X_test, arr_y_test, verbose=True)\n",
    "\n",
    "score_vgg16_seq"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import p5_util\n",
    "import p6_util_plot\n",
    "is_dumped=True\n",
    "if is_dumped is True:\n",
    "    filename = './data/dict_cls_score.dump'\n",
    "    dict_cls_score = p5_util.object_load(filename)\n",
    "else :\n",
    "    pass\n",
    "\n",
    "dict_cls_score['VGG16 Seq'] = score_vgg16_seq\n",
    "dict_benchmark_result = dict_cls_score.copy()\n",
    "\n",
    "df_result = pd.DataFrame.from_dict( dict_benchmark_result, orient='index')\n",
    "df_result.reset_index(inplace=True)\n",
    "df_result.rename(columns={'index':'Classifier',0:'Score'}, inplace=True)\n",
    "df_result\n",
    "nb_images = oP7_DataBreed._sampling_breed_count*oP7_DataBreed._sampling_image_per_breed_count\n",
    "nb_images = oP7_DataBreed.df_pil_image_kpdesc.shape[0]\n",
    "if oP7_DataBreed.is_kp_filtered :\n",
    "    title = \"Benchmark classifiers accuracy / GMM clustering / \"+str(nb_images)+\" filtered splitted images / \"+str(oP7_DataBreed.sampling_breed_count)+\" breeds\"\n",
    "else :\n",
    "    title = \"Benchmark classifiers accuracy / GMM clustering / \"+str(nb_images)+\" splitted images / \"+str(oP7_DataBreed.sampling_breed_count)+\" breeds\"\n",
    "\n",
    "p6_util_plot.ser_item_occurency_plot(df_result.Classifier, df_result.Score*100, item_count=None, title=title,\\\n",
    "                                    p_reverse=False,p_x_title='Classifiers', p_y_title='Accuracy')\n",
    "\n",
    "#### Classifier API\n",
    "p5_util.object_dump(dict_cls_score,filename)\n",
    "\n",
    "dict_cls_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.show()\n",
    "oP7_DataBreed.show_breed_name()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
