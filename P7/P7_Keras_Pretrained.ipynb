{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "if True :\n",
    "    oP7_DataBreed = P7_DataBreed.update_object_save(oP7_DataBreed, is_saved=False,is_new_attribute=True)\n",
    "    oP7_DataBreed.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Object containing data breed model is loaded from dumped file."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "\n",
    "import P7_DataBreed\n",
    "oP7_DataBreed = p5_util.object_load('./data/oP7_DataBreed.dump')\n",
    "oP7_DataBreed.show()\n",
    "oP7_DataBreed.breed_show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>1. Breeds classification using pre-trained VGG16 model</font>\n",
    "`VGG16` is a CNN network provided by / implemented in `Keras` with 16 layers.\n",
    "<br>\n",
    "\n",
    "While convolutional layers are used for features extraction, fully connected layers are used for classification.\n",
    "<br>\n",
    "\n",
    "Those 2 set of layers are used here to classify images as breeds, since breeds have already been learned by network.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "import p5_util\n",
    "\n",
    "filename = './data/vgg16_pretrained.dump'\n",
    "\n",
    "vgg16_pretrained = VGG16() \n",
    "\n",
    "\n",
    "if False :\n",
    "    p5_util.object_dump(vgg16_pretrained,filename)\n",
    "else : \n",
    "    vgg16_pretrained = p5_util.object_load(filename)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(vgg16_pretrained)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### A breed and an image is selected and displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.breed_show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "List of images files names from selected breed is displayed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import P7_DataBreed\n",
    "\n",
    "oP7_DataBreed.show_image_name('Mexican_hairless')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "A selected PIL image is displayed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "\n",
    "import p3_util\n",
    "import p3_util_plot\n",
    "\n",
    "\n",
    "import P7_DataBreed\n",
    "import p7_util\n",
    "\n",
    "breedname='Doberman'\n",
    "imagename='n02107142_16400.jpg'\n",
    "imagename='n02107142_4314.jpg'\n",
    "dirbreed = 'n02107142-Doberman'\n",
    "\n",
    "oP7_DataBreed_single = P7_DataBreed.P7_DataBreed()\n",
    "oP7_DataBreed_single._dict_breed_sample=oP7_DataBreed._dict_breed_sample.copy()\n",
    "\n",
    "list_restricted_image = [(breedname,[imagename])]\n",
    "oP7_DataBreed_single.list_restricted_image = list_restricted_image\n",
    "\n",
    "oP7_DataBreed_single.load(dirbreed=dirbreed, imagename=imagename)\n",
    "\n",
    "p7_util.p7_image_pil_show(oP7_DataBreed_single._dict_img_pil,std_image_size=(500,375), is_title=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Selected image is pre-processed in order to feed pre-trained VGG16 network.\n",
    "\n",
    "Prediction returns `y_pred`, a 1000 sized vector.\n",
    "<br>\n",
    "\n",
    "Built-in function `decode_predictions` allows to provide human readable results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img, img_to_array\n",
    "from keras.applications import vgg16\n",
    "import p3_util_plot\n",
    "\n",
    "image_pathname = oP7_DataBreed._build_pathname(dirbreed,imagename)\n",
    "\n",
    "# Charger l'image PIL\n",
    "pil_image = load_img(image_pathname, target_size=(224, 224))  \n",
    "\n",
    "# Convertir en tableau numpy\n",
    "arr_image = img_to_array(pil_image)  \n",
    "\n",
    "# Créer la collection d'images (un seul échantillon)\n",
    "sample_count=1\n",
    "arr_image = arr_image.reshape((sample_count, arr_image.shape[0], arr_image.shape[1], arr_image.shape[2]))  \n",
    "\n",
    "# Prétraiter l'image comme le veut VGG-16\n",
    "X_test = vgg16.preprocess_input(arr_image)  \n",
    "\n",
    "# Predict image breed thanks to VGG16 pre-trained model\n",
    "y_pred = vgg16_pretrained.predict(X_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Top prediction results are displayed.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Afficher les 3 classes les plus probables\n",
    "top_results = 3\n",
    "print(\"***Breed predictions top \"+str(top_results)+\" results\")\n",
    "[p3_util_plot.printmd(my_tuple) for my_tuple in vgg16.decode_predictions(y_pred, top=top_results)[0]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'> 2. Transfer Learning using `VGG16` pre-trained model</font>\n",
    "\n",
    "Pre-trained model is used as a feature extractor.\n",
    "\n",
    "It as learned discriminative features.\n",
    "\n",
    "We consider we've a few sample to be trained  (3 breeds and close to 120 images) and we want to benefit of features extraction from already trained model.\n",
    "\n",
    "<br>\n",
    "Transfer learning seems to be a proper strategy to achieve classification over a few number of samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Download a VGG16 model that has been pre-trained with imageNet  : \n",
    "* last fully connected layers are removed; in the resulting model only convolutional layers stay.\n",
    "* Image reshape is enforced to (224,224,3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications import VGG16\n",
    " \n",
    "vgg16_pretrained_conv = VGG16(weights='imagenet',\n",
    "                  include_top=False,\n",
    "                  input_shape=(224, 224, 3))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg16_pretrained_conv.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "batch_train_size = 36\n",
    "\n",
    "train_dir = './data/ImagesPretrained/train'\n",
    " \n",
    "datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# train_generator is capable reading images from a given directory.\n",
    "#-----------------------------------------------------------------------------\n",
    "train_generator = datagen.flow_from_directory(\n",
    "    train_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_train_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTrain = 360\n",
    "nClass = 3\n",
    "X_train = np.zeros(shape=(nTrain, 7, 7, 512))\n",
    "y_train = np.zeros(shape=(nTrain,nClass))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features are extracted feeding convolution layers with images issued from train directory.\n",
    "\n",
    "* `y_train` holds encoded classes.\n",
    "* `X_train` holds images used for training model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 0\n",
    "for inputs_batch, labels_batch in train_generator:\n",
    "    \n",
    "    print(\"Batch ID= \"+str(batch_id))\n",
    "    features_batch = vgg16_pretrained_conv.predict(inputs_batch)\n",
    "    X_train[batch_id * batch_train_size : (batch_id + 1) * batch_train_size] = features_batch\n",
    "    y_train[batch_id * batch_train_size : (batch_id + 1) * batch_train_size] = labels_batch\n",
    "    batch_id += 1\n",
    "    if batch_id * batch_train_size >= nTrain:\n",
    "        break\n",
    "         \n",
    "X_train = np.reshape(X_train, (nTrain, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Test dataset is loaded from tets directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from keras.preprocessing import image\n",
    "batch_test_size = 20\n",
    "\n",
    "test_dir  = './data/ImagesPretrained/test'\n",
    " \n",
    "datagen = image.ImageDataGenerator(rescale=1./255)\n",
    "\n",
    "#-----------------------------------------------------------------------------\n",
    "# test_generator is capable reading images from a given directory.\n",
    "#-----------------------------------------------------------------------------\n",
    "test_generator = datagen.flow_from_directory(\n",
    "    test_dir,\n",
    "    target_size=(224, 224),\n",
    "    batch_size=batch_test_size,\n",
    "    class_mode='categorical',\n",
    "    shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Features from Test set are extracted"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nTest = 101\n",
    "\n",
    "X_test = np.zeros(shape=(nTest, 7, 7, 512))\n",
    "y_test = np.zeros(shape=(nTest,nClass))\n",
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_id = 0\n",
    "for inputs_batch, labels_batch in test_generator:\n",
    "    start = batch_id * batch_test_size\n",
    "    end   = start + batch_test_size\n",
    "    remain = X_test.shape[0] - start\n",
    "    \n",
    "    #end = min(end, remain)\n",
    "    print(\"Batch ID= \"+str(batch_id)+\" : start= \"+str(start)+ \" end= \"+str(end)+\" remain= \"+str(remain))\n",
    "    features_batch = vgg16_pretrained_conv.predict(inputs_batch)\n",
    "\n",
    "    if remain < batch_test_size:\n",
    "        end  = start+remain\n",
    "        X_test[start : end] = features_batch[:remain]\n",
    "        y_test[start : end] = labels_batch[:remain]\n",
    "    else :\n",
    "        X_test[start : end] = features_batch\n",
    "        y_test[start : end] = labels_batch\n",
    "    batch_id += 1\n",
    "    if batch_id * batch_test_size >= nTest:\n",
    "        break\n",
    "\n",
    "X_test = np.reshape(X_test, (nTest, 7 * 7 * 512))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_test.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### 2 full connected layers are created in order to complete convolutional layers.\n",
    "\n",
    "3 classes take place in the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "from keras import optimizers\n",
    " \n",
    "model = models.Sequential()\n",
    "# Fist dense layer is compliant with output of last convolutional layer from pre-trained model for transfer learning\n",
    "model.add(layers.Dense(256, activation='relu', input_dim=7 * 7 * 512))\n",
    "model.add(layers.Dropout(0.5))\n",
    "\n",
    "# Last dense layer will classify amont nClass classes.\n",
    "model.add(layers.Dense(nClass, activation='softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model is trained with previous features extracted from convolutional layers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(optimizer=optimizers.RMSprop(lr=1e-3),\n",
    "              loss='categorical_crossentropy',\n",
    "              metrics=['acc'])\n",
    " \n",
    "history = model.fit(X_train,\n",
    "                    y_train,\n",
    "                    epochs=50,\n",
    "                    batch_size=batch_size,\n",
    "                    validation_data=(X_test,y_test))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#Plot the Loss Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['loss'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_loss'],'b',linewidth=1.0)\n",
    "plt.legend(['Training loss', 'Validation Loss'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Loss',fontsize=16)\n",
    "plt.title('Loss Curves ',fontsize=16)\n",
    " \n",
    "#Plot the Accuracy Curves\n",
    "plt.figure(figsize=[8,6])\n",
    "plt.plot(history.history['acc'],'r',linewidth=1.0)\n",
    "plt.plot(history.history['val_acc'],'b',linewidth=1.0)\n",
    "plt.legend(['Training Accuracy', 'Validation Accuracy'],fontsize=18)\n",
    "plt.xlabel('Epochs ',fontsize=16)\n",
    "plt.ylabel('Accuracy',fontsize=16)\n",
    "plt.title('Accuracy Curves',fontsize=16)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Wrongly classified breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fnames = test_generator.filenames\n",
    " \n",
    "ground_truth = test_generator.classes\n",
    " \n",
    "label2index = test_generator.class_indices\n",
    " \n",
    "# Getting the mapping from class index to class label\n",
    "idx2label = dict((v,k) for k,v in label2index.items())\n",
    " \n",
    "predictions = model.predict_classes(X_test)\n",
    "prob = model.predict(X_test)\n",
    " \n",
    "errors = np.where(predictions != ground_truth)[0]\n",
    "print(\"Number of errors = {}/{}\".format(len(errors),nTest))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.image import load_img\n",
    "\n",
    "for i in range(len(errors)):\n",
    "    pred_class = np.argmax(prob[errors[i]])\n",
    "    pred_label = idx2label[pred_class]\n",
    "     \n",
    "    print('Original label:{}, Prediction :{}, confidence : {:.3f}'.format(\n",
    "        fnames[errors[i]].split('/')[0],\n",
    "        pred_label,\n",
    "        prob[errors[i]][pred_class]))\n",
    "     \n",
    "    original = load_img('{}/{}'.format(test_dir,fnames[errors[i]]))\n",
    "    plt.imshow(original)\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "150/600"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.vgg16 import VGG16\n",
    "from keras.layers import Dense\n",
    "import p5_util\n",
    "if False :\n",
    "    # Load ImageNet pre-trained model from VGG-16 \n",
    "    # Option include_top=False leads to remove last Fully connected layer.\n",
    "    # VGG16 model is downloaed from network.\n",
    "    #vgg16_pretrained_model = VGG16(weights=\"imagenet\", include_top=False, input_shape=(224, 224, 3))\n",
    "    vgg16_pretrained_model = VGG16(weights=\"imagenet\", include_top=True, input_shape=(224, 224, 3))\n",
    "    p5_util.object_dump(vgg16_pretrained_model,'./data/vgg16_pretrained_model.dump')\n",
    "else :\n",
    "    vgg16_pretrained_model = p5_util.object_load('./data/vgg16_pretrained_model.dump')\n",
    "vgg16_pretrained_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### An image is selected among breeds"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.breed_show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "breedname='dingo'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP7_DataBreed.show_image_name(breedname, is_sample_show=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.applications.imagenet_utils import decode_predictions\n",
    "from keras.applications import vgg16\n",
    "import p7_util\n",
    "\n",
    "imagename = 'n02115641_4970.jpg'\n",
    "pil_image = oP7_DataBreed.read_image(breedname, imagename)\n",
    "\n",
    "keras_image = p7_util.p7_pil_to_keras_image(pil_image, is_show=True)\n",
    "# prepare the image for the VGG model\n",
    "processed_image = vgg16.preprocess_input(keras_image.copy())\n",
    " \n",
    "# get the predicted probabilities for each class\n",
    "predictions = vgg16_pretrained_model.predict(processed_image)\n",
    "# print predictions\n",
    " \n",
    "# convert the probabilities to class labels\n",
    "# We will get top 5 predictions which is the default\n",
    "pred_breedname_result = decode_predictions(predictions)\n",
    "pred_breedname = pred_breedname_result[0][0][1]\n",
    "pred_proba = pred_breedname_result[0][0][2]*100\n",
    "print(\"Original breed name = \"+breedname+\" / Greatest likehood breed name= \"+str(pred_breedname)+\" Prob={0:0.2F}\".format(pred_proba))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Transfer learning model is built\n",
    "* Output of all layers previous top layer are extracted.\n",
    "* A new fully connected layer (dense layer) is built using previous layer as an input layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras import models\n",
    "from keras import layers\n",
    "\n",
    "# Outputs parameters are retrieved from previous layers\n",
    "vgg16_model_tensor = vgg16_pretrained_model.output\n",
    "\n",
    "# A new fully connected layer is then added in order to classify nbreeds breeds.\n",
    "# Activation function is Softmax; This last layer is applied to the data input vgg16_model_parameters\n",
    "vgg16_fc_tensor = layers.Dense(nbreed, activation='softmax')(vgg16_model_tensor)\n",
    "\n",
    "# New VGG16 model for transfer learning is defined with : \n",
    "# * All layers except last layer are issued from \n",
    "# * fully connected layer previously defined.\n",
    "model_vgg16_transfer_learning = models.Model(inputs=vgg16_pretrained_model.input, outputs=vgg16_fc_tensor)\n",
    "type(model_vgg16_transfer_learning)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Compilation : shape of all internal layers are computed by compiler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compiler le modèle \n",
    "from keras import optimizers\n",
    "\n",
    "model_vgg16_transfer_learning.compile(loss=\"categorical_crossentropy\", optimizer=optimizers.SGD(lr=0.0001, momentum=0.9), metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import p5_util\n",
    "\n",
    "filename='./data/arr_keras_X_y_train_test.dump'\n",
    "(X_train,X_test, y_train, y_test) = p5_util.object_load(filename)\n",
    "print(X_train.shape,X_test.shape,y_train.shape,y_test.shape)\n",
    "if False :\n",
    "    n_xtrain = int((X_train.shape[0]*X_train.shape[1]*X_train.shape[2]*X_train.shape[3])/(7*7*512))\n",
    "    print(n_xtrain)\n",
    "\n",
    "    n_ytrain = int((y_train.shape[0]*y_train.shape[1])/(7*7*512))\n",
    "    print(n_ytrain)\n",
    "\n",
    "    X_train = X_train.reshape((n_xtrain, 7, 7, 512))\n",
    "    #y_train = y_train.reshape((n_ytrain, 7, 7, 512))\n",
    "    print(X_train.shape, y_train.shape)\n",
    "    np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_ytrain = int((y_train.shape[0]*y_train.shape[1])/(7*7*3))\n",
    "print(n_ytrain)\n",
    "y_train.shape,7*7*3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#help(model_vgg16_transfer_learning.fit)\n",
    "model_vgg16_transfer_learning.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Entraîner sur les données d'entraînement (X_train, y_train)\n",
    "model_info = model_vgg16_transfer_learning.fit(X_train, y_train, epochs=1, batch_size=1, verbose=2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Total fine-tuning\n",
    "\n",
    "On remplace la dernière couche fully-connected du réseau pré-entraîné par un classifieur adapté au nouveau problème (SVM, régression logistique...) et initialisé de manière aléatoire. Toutes les couches sont ensuite entraînées sur les nouvelles images. \n",
    "\n",
    "La stratégie #1 doit être utilisée lorsque la nouvelle collection d'images est grande : dans ce cas, on peut se permettre d'entraîner tout le réseau sans courir le risque d'overfitting. De plus, comme les paramètres de toutes les couches (sauf de la dernière) sont initialement ceux du réseau pré-entraîné, la phase d'apprentissage sera faite plus rapidement que si l'initialisation avait été aléatoire."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
