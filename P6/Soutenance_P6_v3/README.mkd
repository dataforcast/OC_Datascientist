# <center><h1>TAG engine proposal for StackOverFlow platform</h1></center>
This project carried out on behalf of the Master 2 Centrale Sup√©lec / Openclassrooms training in datasience
<hr>

<br><br><br>
<h3>Abstract</h3>
<hr>

Stackoverflow allows its users to post problems that they encounter in the implementation of solutions in the field of information technologies. Helpers answer these questions. Questions and Answers form a knowledge base.

<br>

* Project artefacts are located under <a href="URL">http://bit.ly/FBangui_Datascience_NLP</a>
<br>

* The slides present the overall approach of the study : <a href="URL">
        OC_Datascientist/P6/Soutenance_P6_v3/report/Openclassrooms_ParcoursDatascientist_P6-V1.pdf
      </a>
<br>

* Jupyter notebook : <a href="URL">http://bit.ly/NLP_JupyterNotebook</a>
<br>

* Python source code : <a href="URL">http://bit.ly/NLP_Python</a>
<br>

* Project report with detailed exploratory analysis : <a href="URL">http://bit.ly/FBangui_Datascience_slides_TAG</a>
<br>

Description of task to be accomplished along with asumptions are schematized below : 

<center><img src="./P6_Mission.png" alt="Drawing" style="width: 200px;"/></center>

<br>

The problem posed is formulated as that of classifying questions according to the tags which are attributed to them. This classification is then used to suggest the most relevant tags to new questions. 
<br>

Because a question can be assigned with several tags, the classification is approached here from the angle of a **multi-label classification**.
<br>

<h3>Study Overview :</h3>
<hr>

<h4>Exploratory analysis</h4>

* Exploratory analysis leads to build a standardized data model. Scheme below shows how the exploratory analysis has been conducted. It was focused both on Tags and Tokens.

<center><img src="./P6_TAGExploratoryAnalysis.png" alt="Drawing" style="width: 200px;"/></center>

<br>
Tags and tokens show same curve for occurencies.
<center><img src="./P6_TAGandTokenDistribution.png" alt="Drawing" style="width: 200px;"/></center>

<br>
While Kolmogorov/Smirnov statistical inference test over assigned tags lead us to make decision over Gaussian asumption distribution.
<center><img src="./P6_StatInference.png" alt="Drawing" style="width: 200px;"/></center>
<br>

<h4>Standardization process</h4>
<br>
<center><img src="./P6_TokenizationProcess.png" alt="Drawing" style="width: 200px;"/></center>

The left side of the scheme above shows applied functions to lead to corpus standardization.
<br>

The right side of the scheme above provides an exemple of a tokenized post issued from standardization process.
<br>

<u>It is shown that while using NLP algorithms, we've to mainly deal with tokens that are derived from naturel language but do not belongs to naturel language.</u>

<br>
Then, using lemmatization and stems may lead to a bias while training Machine Learning algorithms.

<br>

<h4>Corpus digitalization</h4>

All along this study, multiple algorithms have been used for standardized corpus digitalization : counting tokens, TFIDF, co-occurencies.

<br>
Results lead to a set of features along which, each one of the POST from corpus will be assigned with a set of weights.


<br>
<center><img src="./P6_CorpusDigitalization.png" alt="Drawing" style="width: 200px;"/></center>
<br>



<h4>Benchmarking scheme</h4> 

<br>
Multiple Machine Learning algorithms have been benchmarked in order to select most apropriate one for deployment.

<br>

In addition to M.L. algorithms, statistical algorithms have been added in order to provide a baseline of  results. Scheme below shows the global picture of such benchmark.
<br>
<center><img src="./P6_BenchmarkScope.png" alt="Drawing" style="width: 200px;"/></center>
<br>

**Word2Vec** algorihtm has been regarded here as an expert system. Some tests have shown that **TWord2Vec** was able to predict "better" tags for a given post then the one suggested by users.
<br>

<h4>Statisticals algorithms</h4>
<br>
These methods provide a baseline of results. A measure of accuracy has been defined as showned on scheme below. Multiple digitalization algorithms has been applied such as TF-IDF, token occurencies, N-Grams occurency.


<br>
<center><img src="./P6_StatisticalMethod.png" alt="Drawing" style="width: 200px;"/></center>

<br>
    Results shows accuracy versus digitalization algorithms :
<br>
<center><img src="./P6_StatisticalMethodBenchmark.png" alt="Drawing" style="width: 200px;"/></center>
Best result is reached for  TF-IDF(1,1) with an average accuracy of around 10%. This result is a baseline from which all others algorithms results will be compared with.
<br>

<h4>Unsupervized algotithms : LDA</h4>
<br>
<center><img src="./P6_LDA.png" alt="Drawing" style="width: 200px;"/></center>
<br>Latent Dirichlet Allocation process leads to build 2 matrix : topics distribution over tokens (beta matrix) and POST distribution ovre topics. The former matrix is used for feeding matching algorithm for providing suggested TAGs. The resulted mapped beta matrix shows how same TAGs may belong to different topics. An interpretation may be delivered as follow : combining TAGs lead to cover differents topics. Then (*Linux, C++)* combination may reference developpement of C++ application over Linux platform while *(IOCTL, Linux)* combination probably references developpment of drivers inside Linux kernel.
<br>
<center><img src="./P6_LDAResult.png" alt="Drawing" style="width: 200px;"/></center>
<br>Searching over LDA hyper-parameter that is the number of topics, best accuracy has been reached for 400 topics for an accuracy value of 30%.

<br>

<h4>Unsupervized algorithms : Kmeans clustering</h4>
<br> This sheme detailed below is based on vectorized (digitalized) POST clustering. Similar POSTS may belongs the same cluster. TAGs extraction from any cluster is detailed next.
<center><img src="./P6_Kmeans.png" alt="Drawing" style="width: 200px;"/></center>

<br>Tags extraction is based of distance from a POST to Kmeans cluster centroid. All elements in the cluster are ordered based on distance from cluster centroid. A neighborhood is defined for the POST. Highests TF-IDF value for each neighbour lead to select related Token. Those tokens are filtered from TAGs database for suggested TAGs.


<center><img src="./P6_KmeansTAGExtraction.png" alt="Drawing" style="width: 200px;"/></center>

<br> Searching over Kmeans hyper-parameter that is the number of clusters, best result is shown for 400 clusters for an accuracy value of 16%. Best accuracy value is also reached for 400 clusters, to be compared to LDA results with 400 topics (see above). A possible interpretation is that Kmeans centroid represents the main topic and sub-topics are reached as you moove away from centroid.

<br> The best accuracy result for clusturing with Kmeans has been found around 15%.

<br> Curve on left side shows how inter-cluster inertia decreases along with number of clusters x10.

<center><img src="./P6_KmeansResult.png" alt="Drawing" style="width: 200px;"/></center>

<br>It is shown on the scheme below that accuracy decreases when POST distance from centroid increases.
<center><img src="./P6_KmeansResult2.png" alt="Drawing" style="width: 200px;"/></center>

<h4>Supervized algorithms </h4>
<br>


* Bayse hypothesis

<br> On the scheme below, is is shown that TAG are correlated to each others. TAG combinations leads to address differents topics.

<center><img src="./P6_BayseHypothesis.png" alt="Drawing" style="width: 200px;"/></center>


<br> In order to take into account such correlations, chained supervized algorithms have been evaluated. How it works id detailed on scheme below : at each step, a binary classification problem is solved for Y label. On the following step, Y label is integrated to the input data and a new binary classification problem is solved with the next Y label. 

<center><img src="./P6_ChainedAlgorithms.png" alt="Drawing" style="width: 200px;"/></center>
<br>

<h4>Benchmark results</h4>

* 16 algorithms have been experienced for this benchmark. Most of them provide far more better results then baseline. Weaker results are for Multinomial Naive Bayse, Chained Multinomial Naive Bayse and SVC using a the RBF kernel.
* Results depends on algorithm used to evaluate accuracy.
* LDA / TF-IDF using fuzzy-wuzzy for TAG extraction provide the best results with an accuracy of 35%.
* Logistic Regression algorithm provides the bests score among supervized algorithms for classification. Note that regularization coefficient value shows a strong correlation between features values.
* Showing algorithms performences based on Bayses hypothesis (among them, Multinomial NB, Gaussian NB), it may be suspected that these assumptions are probably wrong for this type of problem.
* Supervized methods suffer from a draw-back : when TAG to be learned are not relevant, then suggested TAG issued from trained supervized algorithms will lead to unexpected results.
* The use of the W2VEC algorithm as an expert system would make it possible to circumvent such drawback  and obtain a more complete evaluation of the benchmarked algorithms with the evaluation of the recall and the F-measurement, in addition to the accuracy measurement.

<center><img src="./P6_BenchmarkResults.png" alt="Drawing" style="width: 200px;"/></center>


<h3>API on JSON format:</h3>
<hr>

* http://127.0.0.1:5000?*
Displays a randomly selected list of POST issued from StackOverFlow database.

* http://127.0.0.1:5000?post_id=<number>
where post_id is a POST identifier picked from result of previous command.



<br>
<h3>Software artefacts</h3>
<hr>

* Classifier object : oP6_PostClassifier.dump
* Application directory for TAG suggestion : tag_suggested
* Launch of Flask server : **cd .../tag_suggested; python3.6 views.py;**
<br>
