{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "    \n",
    "Cette étude a été réalisée dans le cadre du 6ème projet de ma formation Datascientist dispensée en MOOC par \n",
    "\n",
    "<font color='blus'>Openclassrooms / écoles Centrale-Supélec</font>.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Le problème posé :**\n",
    "\n",
    "\n",
    "*Stack Overflow est un site célèbre de question-réponses liées au développement informatique. Pour poser une question sur ce site, il faut entrer plusieurs tags de manière à retrouver facilement la question par la suite. Pour les utilisateurs expérimentés cela ne pose pas de problème, mais pour les nouveaux utilisateurs, il serait judicieux de suggérer quelques tags relatifs à la question posée.*\n",
    "\n",
    "*Amateur de Stack Overflow, qui vous a souvent sauvé la mise, vous décidez d'aider la communauté en retour. Pour cela, vous développez un système de suggestion de tags pour le site. Celui-ci prendra la forme d’un algorithme de machine learning qui assigne automatiquement plusieurs tags pertinents à une question.*\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "The autoreload extension is already loaded. To reload it, use:\n",
      "  %reload_ext autoreload\n"
     ]
    }
   ],
   "source": [
    "from P6_PostClassifier import *\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "Verbose  ................: True\n",
      "Path model name  ........: ./data\n",
      "Nb top words ............: 10\n",
      "LDA topics ..................: 0\n"
     ]
    }
   ],
   "source": [
    "oP6_PostClassifier = P6_PostClassifier(path_to_model='./data')\n",
    "oP6_PostClassifier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/vectorizer_bow.dump\n",
      "p5_util.object_load : fileName= ./data/lda_bow_400topics.dump\n"
     ]
    }
   ],
   "source": [
    "model_name_file = 'lda_bow_400topics.dump'\n",
    "model_name = 'LDA'\n",
    "vectorizer_name = 'BOW'\n",
    "vectorizer_file_name=\"vectorizer_bow.dump\"\n",
    "oP6_PostClassifier.load_model_from_file_name(model_name, model_name_file, vectorizer_name,vectorizer_file_name )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "Verbose  ................: True\n",
      "Path model name  ........: ./data\n",
      "Model name ..............: LDA\n",
      "Model ...................: LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=50.0,\n",
      "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=400, perp_tol=0.1,\n",
      "             random_state=0, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "\n",
      "Vectorizer name ..............: BOW\n",
      "Vectorizer ...................: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.1, max_features=None, min_df=0.001,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "\n",
      "Nb top words ............: 10\n",
      "LDA topics ..................: 0\n"
     ]
    }
   ],
   "source": [
    "oP6_PostClassifier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "oP6_PostClassifier._model_name='LDA'\n",
    "oP6_PostClassifier._vectorizer_name='BOW'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "Verbose  ................: True\n",
      "Path model name  ........: ./data\n",
      "Model name ..............: LDA\n",
      "Model ...................: LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=50.0,\n",
      "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=400, perp_tol=0.1,\n",
      "             random_state=0, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "\n",
      "Vectorizer name ..............: BOW\n",
      "Vectorizer ...................: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.1, max_features=None, min_df=0.001,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "\n",
      "Nb top words ............: 10\n",
      "Current model name  .....: LDA\n",
      "Current vectorizer name .: BOW\n",
      "LDA topics ..................: 0\n"
     ]
    }
   ],
   "source": [
    "oP6_PostClassifier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  \n",
      "Verbose  ................: True\n",
      "Path model name  ........: ./data\n",
      "Model name ..............: LDA\n",
      "Model ...................: LatentDirichletAllocation(batch_size=128, doc_topic_prior=None,\n",
      "             evaluate_every=-1, learning_decay=0.7,\n",
      "             learning_method='online', learning_offset=50.0,\n",
      "             max_doc_update_iter=100, max_iter=5, mean_change_tol=0.001,\n",
      "             n_components=10, n_jobs=None, n_topics=400, perp_tol=0.1,\n",
      "             random_state=0, topic_word_prior=None,\n",
      "             total_samples=1000000.0, verbose=0)\n",
      "\n",
      "Vectorizer name ..............: BOW\n",
      "Vectorizer ...................: CountVectorizer(analyzer='word', binary=False, decode_error='strict',\n",
      "        dtype=<class 'numpy.int64'>, encoding='utf-8', input='content',\n",
      "        lowercase=True, max_df=0.1, max_features=None, min_df=0.001,\n",
      "        ngram_range=(1, 1), preprocessor=None, stop_words=None,\n",
      "        strip_accents=None, token_pattern='(?u)\\\\b\\\\w\\\\w+\\\\b',\n",
      "        tokenizer=None, vocabulary=None)\n",
      "\n",
      "Nb top words ............: 10\n",
      "Current model name  .....: LDA\n",
      "Current vectorizer name .: BOW\n",
      "LDA topics ..............: 400\n"
     ]
    }
   ],
   "source": [
    "oP6_PostClassifier.update_model()\n",
    "oP6_PostClassifier.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "file_name=\"./data/test_StackOverFlow_BodyTitleTags.csv\"\n",
    "df_sof_test=pd.read_csv(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['php5', 'class', 'singleton', 'pattern', 'design']"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sample = df_sof_test.sample()\n",
    "body = df_sample.Body.iloc[0]\n",
    "title=df_sample.Title.iloc[0]\n",
    "tags = df_sample.Tags.iloc[0]\n",
    "\n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "oP6_PostClassifier.suggest(body, title)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<php><oop><design-patterns><singleton>\n"
     ]
    }
   ],
   "source": [
    "print(tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<p>How would one create a Singleton class using PHP5 classes?</p>\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
