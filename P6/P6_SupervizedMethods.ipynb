{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "-"
    }
   },
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "    \n",
    "Cette étude a été réalisée dans le cadre du 6ème projet de ma formation Datascientist dispensée en MOOC par \n",
    "\n",
    "<font color='blus'>Openclassrooms / écoles Centrale-Supélec</font>.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "<p></p><p></p><p></p>\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "**Le problème posé :**\n",
    "\n",
    "\n",
    "*Stack Overflow est un site célèbre de question-réponses liées au développement informatique. Pour poser une question sur ce site, il faut entrer plusieurs tags de manière à retrouver facilement la question par la suite. Pour les utilisateurs expérimentés cela ne pose pas de problème, mais pour les nouveaux utilisateurs, il serait judicieux de suggérer quelques tags relatifs à la question posée.*\n",
    "\n",
    "*Amateur de Stack Overflow, qui vous a souvent sauvé la mise, vous décidez d'aider la communauté en retour. Pour cela, vous développez un système de suggestion de tags pour le site. Celui-ci prendra la forme d’un algorithme de machine learning qui assigne automatiquement plusieurs tags pertinents à une question.*\n",
    "\n",
    "\n",
    "\n",
    "**Solutions mises en oeuvre**\n",
    "\n",
    "Les solutions de suggestion de tags présentés ici se basent sur des modèles supervisés de machine learning.\n",
    "\n",
    "Les modèmes mis en oeuvre : \n",
    "    * Naive Multinomial Baysien\n",
    "\n",
    "Ce notebook utilise les données issues des notebooks : \n",
    "\n",
    "\n",
    "**P6_DadaAnalysis.ipynb**\n",
    "\n",
    "**P6_UnsupervizedMethods.ipynb**\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "%reload_ext autoreload"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Supervized methods"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading TF-IDF operator and CSR matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/csr_matrix_tdif_ngram_2_2.dump\n",
      "(16359, 898)\n",
      "p5_util.object_load : fileName= ./data/vectorizer_tdif_ngram_2_2.dump\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "file_name=\"./data/csr_matrix_tdif_ngram_2_2.dump\"\n",
    "csr_matrix = p5_util.object_load(file_name)\n",
    "print(csr_matrix.shape)\n",
    "\n",
    "file_name=\"./data/vectorizer_tdif_ngram_2_2.dump\"\n",
    "vectorizer = p5_util.object_load(file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.1. Test dataset vectorization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16359, 5)\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_name=\"./data/test_StackOverFlow_BodyTitleTags.csv\"\n",
    "df_sof_test=pd.read_csv(file_name)\n",
    "print(df_sof_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Test dataset standardization : applies on `Body` column**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['Id', 'PostTypeId', 'Body', 'Title', 'Tags'], dtype='object')"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sof_test.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Cleaning text in-between markers <code></code> markers...\n",
      "\n",
      "Cleaning LXML markers...\n",
      "\n",
      "Remove verbs from sentences...\n",
      "\n",
      "Filtering alpha-numeric words from sentences...\n",
      "\n",
      "Removing stopwords...\n",
      "\n",
      "Lemmatization ...\n"
     ]
    }
   ],
   "source": [
    "import p6_util\n",
    "ser_sof_body_test = p6_util.p6_df_standardization(df_sof_test.Body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix_tdif_ngram_2_2_test = vectorizer.transform(ser_sof_body_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16359, 898), (16359, 5))"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix_tdif_ngram_2_2_test.A.shape, df_sof_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save of test CSR matrix**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_name=\"./data/csr_matrix_tdif_ngram_2_2_test.dump\"\n",
    "p5_util.object_dump(csr_matrix_tdif_ngram_2_2_test,file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.2. Target processing : list of TAGS are encoded"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.1. Target : TAGs for train dataset are loaded and formated"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(24604,)"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "file_name=\"./data/train_StackOverFlow_BodyTitleTags.csv\"\n",
    "ser_sof_train_tags=pd.read_csv(file_name).Tags.copy()\n",
    "ser_sof_train_tags.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Series is resized to fit with Test dataset**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16359,)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ser_sof_train_tags = ser_sof_train_tags[:csr_matrix.shape[0]]\n",
    "ser_sof_train_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Tags are converted into a lists of words.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy import sparse\n",
    "import p6_util\n",
    "def p6_encode_ser_tag_2_csrmatrix(ser_tag):\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # Markers '<' and '>' are removed from tags.\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    ser_tag = ser_tag.apply(p6_util.clean_marker_text, leading_marker='<', trailing_marker='>')\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # A unique list of all TAGs is built : this is the vocabulary for TAGs**\n",
    "    # This list is supposed to be completed enough for covering test tags dataset.\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    list_all_tags = p6_util.p6_get_list_all_tag(ser_tag)\n",
    "    \n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # For each row, TAGs represented as a list of elementaries TAG are encoded\n",
    "    # Each row that is a string of TAGs is splitted into a list of elementary TAGs\n",
    "    # All rows are aggregated into a list\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    list_list_encoded_row = p6_util.p6_encode_target(list_all_tags, ser_tag.tolist())\n",
    "\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    # Conversion into CSR matrix fro easyness of computation\n",
    "    #-----------------------------------------------------------------------------------------\n",
    "    csr_matrix_encoded_tag=sparse.csr_matrix(np.array(list_list_encoded_row))\n",
    "    return csr_matrix_encoded_tag"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix_encoded_train_tags = p6_encode_ser_tag_2_csrmatrix(ser_sof_train_tags)"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "**Simple test for checking some random encoded rows**"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "import numpy as np\n",
    "import p6_util\n",
    "\n",
    "row=np.random.randint(0, len(list_list_encoded_row))\n",
    "print(\"Row =\"+str(row)+\" / \"+str(len(list_list_encoded_row)))\n",
    "print(p6_util.p6_get_list_tag_from_encoded_row(list_list_encoded_row,row,list_all_tags))\n",
    "print(ser_sof_train_tags[row])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Save of encoded train-dataset target**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(16359, 5155)\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "\n",
    "file_name=\"./data/csr_matrix_encoded_train_tags.dump\"\n",
    "p5_util.object_dump(csr_matrix_encoded_train_tags,file_name)\n",
    "print(csr_matrix_encoded_train_tags.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4.3. Applying Naive Bayes classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.1. Training classifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading TF-IDF data-set containing trained vectorized questions**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/csr_matrix_tdif_ngram_2_2.dump\n",
      "(16359, 898)\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "\n",
    "file_name=\"./data/csr_matrix_tdif_ngram_2_2.dump\"\n",
    "csr_matrix_tdif_ngram_2_2 = p5_util.object_load(file_name)\n",
    "print(csr_matrix_tdif_ngram_2_2.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading target train data-set containing encoded TAGs**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/csr_matrix_encoded_train_tags.dump\n",
      "(16359, 5155)\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "\n",
    "file_name=\"./data/csr_matrix_encoded_train_tags.dump\"\n",
    "csr_matrix_encoded_train_target = p5_util.object_load(file_name)\n",
    "print(csr_matrix_encoded_train_target.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Training classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "one versus Rest leads having one classifier per class.\n",
    "\n",
    "`OneVsRestClassifier` classifier is used because of multiple classes. \n",
    "\n",
    "Then, one classifier per class is fitted.\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "import numpy as np\n",
    "\n",
    "model = OneVsRestClassifier(MultinomialNB(), n_jobs=4).fit(csr_matrix_tdif_ngram_2_2, csr_matrix_encoded_train_target)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.3.2.Classifier evaluation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading test data-set**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "p5_util.object_load : fileName= ./data/csr_matrix_tdif_ngram_2_2_test.dump\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(16359, 898)"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_name=\"./data/csr_matrix_tdif_ngram_2_2_test.dump\"\n",
    "csr_matrix_tdif_ngram_2_2_test = p5_util.object_load(file_name)\n",
    "csr_matrix_tdif_ngram_2_2_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=4)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Predictions and probabilities**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix_encoded_predict_tags = model.predict(csr_matrix_tdif_ngram_2_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([], dtype=int64), array([], dtype=int64))"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.where(csr_matrix_encoded_predict_tags[1000].A!=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**<font color=blue>P({Tag_i}|Question)</font>**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix_encoded_predict_proba_tags = model.predict_proba(csr_matrix_tdif_ngram_2_2_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([6.11284308e-05, 4.76801760e-03, 1.83385292e-04, ...,\n",
       "       6.11284308e-05, 6.11284308e-05, 5.50155877e-04])"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "np.where(csr_matrix_encoded_predict_proba_tags[1000]!=0)\n",
    "csr_matrix_encoded_predict_proba_tags[1000]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Compute accuracy**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(16359,)"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_sof_test.columns\n",
    "ser_sof_test_tags=df_sof_test['Tags']\n",
    "ser_sof_test_tags.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Tests TAGs are encoed then converted into CSR matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "csr_matrix_encoded_test_tags = p6_encode_ser_tag_2_csrmatrix(ser_sof_test_tags)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((16359, 898), (16359, 5547), (16359, 5155))"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "csr_matrix_tdif_ngram_2_2_test.shape, csr_matrix_encoded_test_tags.shape,csr_matrix_encoded_predict_tags.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean score for Multinomial Naive Bayse classifier : 0.010086191087474784\n"
     ]
    }
   ],
   "source": [
    "score = model.score(csr_matrix_tdif_ngram_2_2_test ,csr_matrix_encoded_test_tags[:,:5155])\n",
    "print(\"Mean score for Multinomial Naive Bayse classifier : \"+str(score))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
