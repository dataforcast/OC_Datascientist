{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "<p>\n",
    "Cette activité est réalisée dans le cadre du cours **``Analysez vos données textuelles``** diffusé en MOOC par\n",
    "**<font color='blus'>Openclassrooms</font>**.\n",
    "</p>\n",
    "...   \n",
    "<p>\n",
    "...   \n",
    "</p>\n",
    "\n",
    "**Consignes**: \n",
    "\n",
    "* Charger les données\n",
    "* Créer différents classifieurs (au moins 3)\n",
    "* Effectuer une validation croisée sur les différents classifieurs\n",
    "* Afficher les différentes performances\n",
    "\n",
    "<p>\n",
    "Le jeu de données est relativement lourd pour un travail en local, avec 650MB compressé de données. Il est conseillé de travailler sur un échantillon dans un premier temps pour s’assurer que tout fonctionne comme prévu pour ensuite traiter tout le jeu de données et obtenir les résultats finaux.    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "# Constants for this notebook\n",
    "#-------------------------------------------------------------------------------\n",
    "file_name_train = './data/rcv1_train.dump'\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def split_train_test(X,y,train_ratio):\n",
    "    train_range= int(X.shape[0]*train_ratio)\n",
    "    X_train=X[:train_range]\n",
    "    X_test=X[train_range:]\n",
    "    \n",
    "    y_train=y[:train_range]\n",
    "    y_test=y[train_range:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def get_encoded_target(data_target):\n",
    "    list_str_target=list()\n",
    "    for row in range(0,data_target.shape[0]):\n",
    "        list_str=[str(weight) for weight in np.array(data_target[row].todense())[0]]\n",
    "        str_target = ''.join(list_str)\n",
    "        list_str_target.append(str_target)    \n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    list_encoded_target=le.fit_transform(list_str_target)\n",
    "    return list_encoded_target, le\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def compute_accuracy_per_target(y_test, y_pred, list_target):\n",
    "   \"\"\"Computes and display global accurency predictions and per target \n",
    "      accurency predictions.\n",
    "      \n",
    "      Function used for accurency is metrics.accuracy_score\n",
    "      Input : \n",
    "         * y_test : vector to be tested\n",
    "         * y_pred : vector issues from prediction model\n",
    "         * list_cluster : list of market segments found with unsupervised M.L.\n",
    "         algorithm.\n",
    "      Output : none\n",
    "   \"\"\"\n",
    "\n",
    "   #----------------------------------------------------------\n",
    "   # Global accuracy is computed\n",
    "   #----------------------------------------------------------\n",
    "   score_global=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "   dict_score_target=dict()\n",
    "   for i_target in list_target :\n",
    "       #----------------------------------------------------------\n",
    "       # Get tuple of array indexes matching with target\n",
    "       #----------------------------------------------------------\n",
    "       index_tuple=np.where( y_pred==i_target )\n",
    "\n",
    "       #----------------------------------------------------------\n",
    "       # Extract values thanks to array of indexes \n",
    "       #----------------------------------------------------------\n",
    "       y_test_target=y_test[index_tuple[0]]\n",
    "       y_pred_target=y_pred[index_tuple[0]]\n",
    "       \n",
    "       nb_elt_target=len(y_test_target)\n",
    "       \n",
    "       #----------------------------------------------------------\n",
    "       # Accuracy is computed and displayed\n",
    "       #----------------------------------------------------------\n",
    "       score_target=metrics.accuracy_score(y_test_target, y_pred_target)\n",
    "       dict_score_target[i_target]=score_target\n",
    "       #print(\"Segment \"+str(i_segment)+\" : \"+str(nb_elt_segment)\\\n",
    "       #+\" elts / Random forest / Précision: {0:1.2F}\".format(score))\n",
    "   return score_global,dict_score_target\n",
    "#-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>1. Data acquisition</font>\n",
    "\n",
    "**From http://scikit-learn.org/stable/datasets/rcv1.html**\n",
    "\n",
    "``data``: The feature matrix is a scipy CSR sparse matrix, with 804414 samples and 47236 features. Non-zero values contains cosine-normalized, log TF-IDF vectors. \n",
    "\n",
    "A nearly chronological split is proposed in [1]: \n",
    "\n",
    "* The first 23149 samples are the training set. \n",
    "* The last 781265 samples are the testing set. \n",
    "\n",
    "This follows the official LYRL2004 chronological split. \n",
    "\n",
    "The array has 0.16% of non zero values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get train dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCV1 : Reuters Corpus Volume I \n",
    "from sklearn.datasets import fetch_rcv1\n",
    "rcv1_train = fetch_rcv1(subset='train')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dump train dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "file_name = file_name_train\n",
    "p5_util.object_dump(rcv1_train, file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1_train.target_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Get test dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# RCV1 : Reuters Corpus Volume I \n",
    "from sklearn.datasets import fetch_rcv1\n",
    "rcv1_test = fetch_rcv1(subset='test')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1_test.keys(),rcv1_test.data.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dump test dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "data_path = \"./data\"\n",
    "core_name = \"rcv1_test\"\n",
    "\n",
    "p5_util.bunch_dump(rcv1_test, 100000, data_path, core_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dumped test dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "data_path = \"./data\"\n",
    "core_name = \"rcv1_test\"\n",
    "list_key = ['data', 'target', 'sample_id', 'target_names',]\n",
    "data_len=781265\n",
    "row_packet=100000\n",
    "dict_rcv1_test = p5_util.bunch_load(list_key, data_len, row_packet, data_path, core_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>2. Applying Multinomial Bayes model</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "model = MultinomialNB()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "./data/rcv1_train.dump\n",
      "\n",
      "p5_util.object_load : fileName= ./data/rcv1_train.dump\n",
      "dict_keys(['data', 'target', 'sample_id', 'target_names', 'DESCR'])\n",
      "(23149, 47236)\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "print(file_name_train+str(\"\\n\"))\n",
    "rcv1_train = p5_util.object_load(file_name_train)\n",
    "\n",
    "print(rcv1_train.keys())\n",
    "print(rcv1_train.data.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['C11', 'C12', 'C13', 'C14', 'C15', 'C151', 'C1511', 'C152', 'C16',\n",
       "       'C17', 'C171', 'C172', 'C173', 'C174', 'C18', 'C181', 'C182',\n",
       "       'C183', 'C21', 'C22', 'C23', 'C24', 'C31', 'C311', 'C312', 'C313',\n",
       "       'C32', 'C33', 'C331', 'C34', 'C41', 'C411', 'C42', 'CCAT', 'E11',\n",
       "       'E12', 'E121', 'E13', 'E131', 'E132', 'E14', 'E141', 'E142',\n",
       "       'E143', 'E21', 'E211', 'E212', 'E31', 'E311', 'E312', 'E313',\n",
       "       'E41', 'E411', 'E51', 'E511', 'E512', 'E513', 'E61', 'E71', 'ECAT',\n",
       "       'G15', 'G151', 'G152', 'G153', 'G154', 'G155', 'G156', 'G157',\n",
       "       'G158', 'G159', 'GCAT', 'GCRIM', 'GDEF', 'GDIP', 'GDIS', 'GENT',\n",
       "       'GENV', 'GFAS', 'GHEA', 'GJOB', 'GMIL', 'GOBIT', 'GODD', 'GPOL',\n",
       "       'GPRO', 'GREL', 'GSCI', 'GSPO', 'GTOUR', 'GVIO', 'GVOTE', 'GWEA',\n",
       "       'GWELF', 'M11', 'M12', 'M13', 'M131', 'M132', 'M14', 'M141',\n",
       "       'M142', 'M143', 'MCAT'], dtype=object)"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target_names = rcv1_train.target_names\n",
    "target_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(23149, 103)\n"
     ]
    }
   ],
   "source": [
    "print(rcv1_train.target.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rcv1_train.target[20].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1000, 103)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import numpy as np\n",
    "rcv1_train.target[:10,0].A.reshape(1,-1)\n",
    "\n",
    "#target = np.arange(0, rcv1_train.target.shape[0])\n",
    "target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "data1 =rcv1_train.data[:1000,:500]\n",
    "target1= target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0,\n",
       "        0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]], dtype=uint8)"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "target1[10].A"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "model = OneVsRestClassifier(MultinomialNB())\n",
    "#model = MultinomialNB()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "OneVsRestClassifier(estimator=MultinomialNB(alpha=1.0, class_prior=None, fit_prior=True),\n",
       "          n_jobs=1)"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1_train.target.shape, rcv1_train.target_names.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>XX. Train dataset pre-processing</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Load dumped train dataset corpus**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "print(file_name_train+str(\"\\n\"))\n",
    "rcv1_train = p5_util.object_load(file_name_train)\n",
    "\n",
    "print(rcv1_train.keys())\n",
    "print(rcv1_train.data.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>2.1 Target processing</font>\n",
    "\n",
    "Target from loaded dataset is a matrix with more then 100 features.\n",
    "\n",
    "The goal of the process here under is to reduce target dimensions while creating a single vector as target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1_train.target.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "list_new_feature_target_name = list()\n",
    "print( rcv1_train.target.A.shape)\n",
    "for ind, array_tag in enumerate(rcv1_train.target.A):\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # For any raw, an index filter is created from columns with value flag fixed to 1.\n",
    "    #---------------------------------------------------------------------------------\n",
    "    index_filter = np.where(array_tag==1)\n",
    "\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # Index filter is applied to target_names and the list of target names for this \n",
    "    # raw is returned.\n",
    "    #---------------------------------------------------------------------------------\n",
    "    list_raw_target_name = np.array(rcv1_train.target_names)[index_filter]\n",
    "\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # New target feature is created for the current raw.\n",
    "    #---------------------------------------------------------------------------------\n",
    "    feature_target_name = ' '.join(list_raw_target_name)\n",
    "\n",
    "    #---------------------------------------------------------------------------------\n",
    "    # This new feature is stored\n",
    "    #---------------------------------------------------------------------------------\n",
    "    list_new_feature_target_name.append(feature_target_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "list_new_feature_target_name[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "le = preprocessing.LabelEncoder()\n",
    "list_new_feature_target_encoded=le.fit_transform(list_new_feature_target_name)\n",
    "len(np.unique(list_new_feature_target_encoded)),len(rcv1_train.target.A)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blue'>2.1 Dataset processing</font>\n",
    "\n",
    "A PCA analysis is conducted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rcv1_train.data.shape[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "index_filter=np.random.choice(np.arange(0,rcv1_train.data.shape[0]), size=1000)\n",
    "part_rcv1_train = rcv1_train.data[index_filter]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "type(part_rcv1_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p3_util_plot\n",
    "z__ = p3_util_plot.pca_all_plot(part_rcv1_train.todense(), plot=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Train corpus is splited into 2 parts : train and test."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ratio=0.7\n",
    "X_train, X_test, y_train, y_test= split_train_test(rcv1_train.data,rcv1_train.target, train_ratio)\n",
    "print(X_train.shape, X_test.shape, y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_train, le_train = get_encoded_target(y_train)\n",
    "y_test, le_test = get_encoded_target(y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Random Forest classifier**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "nb_estimators = 10\n",
    "rfc = RandomForestClassifier(n_estimators=nb_estimators)\n",
    "rfc_model = rfc.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_predict = rfc_model.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "len(y_predict),X_test.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "type(y_train)\n",
    "list_target = np.unique(y_train)\n",
    "len(list_target), len(np.unique(y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Performances **:\n",
    "* score_global : this is the mean accuracy \n",
    "* dict_score_target: is the accuracy prediction per target."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "score_global, dict_score_target = compute_accuracy_per_target(y_test, y_predict,list_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "np.unique(y_predict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy= {}\".format(score_global))\n",
    "dict_score_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**SGD classifier**\n",
    "\n",
    "Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "import p5_util\n",
    "\n",
    "sgdcl = SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)\n",
    "sgdcl_model = sgdcl.fit(X_train, y_train)\n",
    "\n",
    "y_predict = sgdcl_model.predict(X_test)\n",
    "score_global, dict_score_target = p5_util.compute_precision_per_segment(y_test, y_predict,list_target)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"Mean accuracy= {}\".format(score_global))\n",
    "dict_score_target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Naive Baysien Classifier**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Loading test bunch**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "bunch_data = p5_util.object_load_split(800000,100000,'./data','rcv1_test')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
