{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<!--NOTEBOOK_INFORMATION-->\n",
    "<img align=\"left\" style=\"padding-right:10px;\" src=\"./figures/LogoOpenclassrooms.png\">\n",
    "<font size=\"4\">\n",
    "<p>\n",
    "Cette activité est réalisée dans le cadre du cours **``Analysez vos données textuelles``** diffusé en MOOC par\n",
    "**<font color='blus'>Openclassrooms</font>**.\n",
    "</p>\n",
    "...   \n",
    "<p>\n",
    "...   \n",
    "</p>\n",
    "\n",
    "**Consignes**: \n",
    "\n",
    "* Charger les données\n",
    "* Créer différents classifieurs (au moins 3)\n",
    "* Effectuer une validation croisée sur les différents classifieurs\n",
    "* Afficher les différentes performances\n",
    "\n",
    "<p>\n",
    "Le jeu de données est relativement lourd pour un travail en local, avec 650MB compressé de données. Il est conseillé de travailler sur un échantillon dans un premier temps pour s’assurer que tout fonctionne comme prévu pour ensuite traiter tout le jeu de données et obtenir les résultats finaux.    \n",
    "</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "#-------------------------------------------------------------------------------\n",
    "# Constants for this notebook\n",
    "#-------------------------------------------------------------------------------\n",
    "file_name_train = './data/rcv1_train.dump'\n",
    "IS_LOCAL_DATASET=True\n",
    "N_JOBS=-1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn import preprocessing\n",
    "from sklearn import metrics\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def split_train_test(X,y,train_ratio):\n",
    "    train_range= int(X.shape[0]*train_ratio)\n",
    "    X_train=X[:train_range]\n",
    "    X_test=X[train_range:]\n",
    "    \n",
    "    y_train=y[:train_range]\n",
    "    y_test=y[train_range:]\n",
    "    return X_train, X_test, y_train, y_test\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def get_encoded_target(data_target):\n",
    "    list_str_target=list()\n",
    "    for row in range(0,data_target.shape[0]):\n",
    "        list_str=[str(weight) for weight in np.array(data_target[row].todense())[0]]\n",
    "        str_target = ''.join(list_str)\n",
    "        list_str_target.append(str_target)    \n",
    "\n",
    "    le = preprocessing.LabelEncoder()\n",
    "    list_encoded_target=le.fit_transform(list_str_target)\n",
    "    return list_encoded_target, le\n",
    "#-------------------------------------------------------------------------------\n",
    "\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def compute_accuracy_per_target(y_test, y_pred, list_target):\n",
    "   \"\"\"Computes and display global accurency predictions and per target \n",
    "      accurency predictions.\n",
    "      \n",
    "      Function used for accurency is metrics.accuracy_score\n",
    "      Input : \n",
    "         * y_test : vector to be tested\n",
    "         * y_pred : vector issues from prediction model\n",
    "         * list_cluster : list of market segments found with unsupervised M.L.\n",
    "         algorithm.\n",
    "      Output : none\n",
    "   \"\"\"\n",
    "\n",
    "   #----------------------------------------------------------\n",
    "   # Global accuracy is computed\n",
    "   #----------------------------------------------------------\n",
    "   score_global=metrics.accuracy_score(y_test, y_pred)\n",
    "\n",
    "\n",
    "   dict_score_target=dict()\n",
    "   for i_target in list_target :\n",
    "       #----------------------------------------------------------\n",
    "       # Get tuple of array indexes matching with target\n",
    "       #----------------------------------------------------------\n",
    "       index_tuple=np.where( y_pred==i_target )\n",
    "\n",
    "       #----------------------------------------------------------\n",
    "       # Extract values thanks to array of indexes \n",
    "       #----------------------------------------------------------\n",
    "       y_test_target=y_test[index_tuple[0]]\n",
    "       y_pred_target=y_pred[index_tuple[0]]\n",
    "       \n",
    "       nb_elt_target=len(y_test_target)\n",
    "       \n",
    "       #----------------------------------------------------------\n",
    "       # Accuracy is computed and displayed\n",
    "       #----------------------------------------------------------\n",
    "       score_target=metrics.accuracy_score(y_test_target, y_pred_target)\n",
    "       dict_score_target[i_target]=score_target\n",
    "       #print(\"Segment \"+str(i_segment)+\" : \"+str(nb_elt_segment)\\\n",
    "       #+\" elts / Random forest / Précision: {0:1.2F}\".format(score))\n",
    "   return score_global,dict_score_target\n",
    "#-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>1. Data acquisition</font>\n",
    "\n",
    "**From http://scikit-learn.org/stable/datasets/rcv1.html**\n",
    "\n",
    "``data``: The feature matrix is a scipy CSR sparse matrix, with 804414 samples and 47236 features. \n",
    "\n",
    "Non-zero values contains cosine-normalized, log TF-IDF vectors. \n",
    "\n",
    "A nearly chronological split is proposed in [1]: \n",
    "\n",
    "* The first 23149 samples are the training set. \n",
    "* The last 781265 samples are the testing set. \n",
    "\n",
    "This follows the official LYRL2004 chronological split. \n",
    "\n",
    "The array has 0.16% of non zero values:"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.1. Loading train dataset </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Loading local train dataset ...\n",
      "./data/rcv1_train.dump\n",
      "\n",
      "p5_util.object_load : fileName= ./data/rcv1_train.dump\n",
      "\n",
      "*** Local train dataset loaded!\n",
      "\n",
      "*** Train target : (103,)\n",
      "\n",
      "*** Train data : (23149, 47236)\n"
     ]
    }
   ],
   "source": [
    "# RCV1 : Reuters Corpus Volume I \n",
    "from sklearn.datasets import fetch_rcv1\n",
    "\n",
    "import p5_util\n",
    "\n",
    "if IS_LOCAL_DATASET is False:\n",
    "    #------------------------------------------------------------------------\n",
    "    # Loading train dataset\n",
    "    #------------------------------------------------------------------------\n",
    "    rcv1_train = fetch_rcv1(subset='train')\n",
    "    file_name = file_name_train\n",
    "    #------------------------------------------------------------------------\n",
    "    # Dumping train dataset\n",
    "    #------------------------------------------------------------------------\n",
    "    p5_util.object_dump(rcv1_train, file_name)\n",
    "else:\n",
    "    print(\"\\n*** Loading local train dataset ...\")\n",
    "    print(file_name_train+str(\"\\n\"))\n",
    "    rcv1_train = p5_util.object_load(file_name_train)\n",
    "    print(\"\\n*** Local train dataset loaded!\")\n",
    "\n",
    "print(\"\\n*** Train target : \"+str(rcv1_train.target_names.shape))\n",
    "print(\"\\n*** Train data : \"+str(rcv1_train.data.shape))\n",
    "\n",
    "X_train = rcv1_train.data\n",
    "y_train = rcv1_train.target"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>1.2. Loading test dataset from corpus</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "*** Loading local test dataset ...\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_0.dump\n",
      "./data/rcv1_test_data_0.dump (100000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_1.dump\n",
      "./data/rcv1_test_data_1.dump (200000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_2.dump\n",
      "./data/rcv1_test_data_2.dump (300000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_3.dump\n",
      "./data/rcv1_test_data_3.dump (400000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_4.dump\n",
      "./data/rcv1_test_data_4.dump (500000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_5.dump\n",
      "./data/rcv1_test_data_5.dump (600000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_6.dump\n",
      "./data/rcv1_test_data_6.dump (700000, 47236)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_data_7.dump\n",
      "./data/rcv1_test_data_7.dump (781258, 47236)\n",
      "\n",
      " Loading splited file done!\n",
      "\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_0.dump\n",
      "./data/rcv1_test_target_0.dump (100000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_1.dump\n",
      "./data/rcv1_test_target_1.dump (200000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_2.dump\n",
      "./data/rcv1_test_target_2.dump (300000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_3.dump\n",
      "./data/rcv1_test_target_3.dump (400000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_4.dump\n",
      "./data/rcv1_test_target_4.dump (500000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_5.dump\n",
      "./data/rcv1_test_target_5.dump (600000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_6.dump\n",
      "./data/rcv1_test_target_6.dump (700000, 103)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_7.dump\n",
      "./data/rcv1_test_target_7.dump (781258, 103)\n",
      "\n",
      " Loading splited file done!\n",
      "\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_0.dump\n",
      "./data/rcv1_test_sample_id_0.dump (100000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_1.dump\n",
      "./data/rcv1_test_sample_id_1.dump (200000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_2.dump\n",
      "./data/rcv1_test_sample_id_2.dump (300000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_3.dump\n",
      "./data/rcv1_test_sample_id_3.dump (400000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_4.dump\n",
      "./data/rcv1_test_sample_id_4.dump (500000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_5.dump\n",
      "./data/rcv1_test_sample_id_5.dump (600000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_6.dump\n",
      "./data/rcv1_test_sample_id_6.dump (700000,)\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_sample_id_7.dump\n",
      "./data/rcv1_test_sample_id_7.dump (781258,)\n",
      "\n",
      " Loading splited file done!\n",
      "\n",
      "p5_util.object_load : fileName= ./data/rcv1_test_target_names_0.dump\n",
      "./data/rcv1_test_target_names_0.dump (103,)\n",
      "\n",
      " Loading splited file done!\n",
      "\n",
      "\n",
      "*** Local test dataset loaded!\n",
      "\n",
      "*** Test dataset dictionary keys : dict_keys(['data', 'target', 'sample_id', 'target_names'])\n",
      "\n",
      "*** Test target sizing : (103,)\n",
      "\n",
      "*** Test data sizing : (781258, 47236)\n"
     ]
    }
   ],
   "source": [
    "import p5_util\n",
    "\n",
    "data_path = \"./data\"\n",
    "core_name = \"rcv1_test\"\n",
    "\n",
    "# RCV1 : Reuters Corpus Volume I \n",
    "from sklearn.datasets import fetch_rcv1\n",
    "data_path = \"./data\"\n",
    "core_name = \"rcv1_test\"\n",
    "\n",
    "if IS_LOCAL_DATASET is False:\n",
    "    #------------------------------------------------------------------------\n",
    "    # Loading test dataset\n",
    "    #------------------------------------------------------------------------\n",
    "    rcv1_test = fetch_rcv1(subset='test')\n",
    "    print(rcv1_test.keys(),rcv1_test.data.shape)\n",
    "    \n",
    "    #------------------------------------------------------------------------\n",
    "    # Dumping test dataset\n",
    "    #------------------------------------------------------------------------\n",
    "    p5_util.bunch_dump(rcv1_test, 100000, data_path, core_name)    \n",
    "else:\n",
    "    print(\"\\n*** Loading local test dataset ...\")\n",
    "    list_key = ['data', 'target', 'sample_id', 'target_names',]\n",
    "    data_len=781265\n",
    "    row_packet=100000\n",
    "    dict_rcv1_test = p5_util.bunch_load(list_key, data_len, row_packet, data_path, core_name)\n",
    "    print(\"\\n*** Local test dataset loaded!\")\n",
    "\n",
    "print(\"\\n*** Test dataset dictionary keys : \"+str(dict_rcv1_test.keys()))\n",
    "print(\"\\n*** Test target sizing : \"+str(dict_rcv1_test['target_names'].shape))\n",
    "print(\"\\n*** Test data sizing : \"+str(dict_rcv1_test['data'].shape))\n",
    "\n",
    "X_test = dict_rcv1_test['data']\n",
    "y_test = dict_rcv1_test['target']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# <font color='blus'>2. Applying classifiers over dataset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Classsifiers score are stored into dictionary**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score=dict()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.1. Multinomial Naive Bayes classifier with binary relevance</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Due to multiple targets classes, `OneVsRestClassifier` classifier is applied on Multinomial Naive Bayes classifier. \n",
    "\n",
    "One classifier per class is fitted.\n",
    "\n",
    "**Note : change N_JOBS value if required. Default value is fixed to 8.** \n",
    "\n",
    "*See constants assignation into fisrt cells from this notebook.*"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.1.1. Training Multinomial Naive Bayes classifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "One versus Rest transformation ispallied Naive Bayes classifier."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "classifier_mnb = OneVsRestClassifier(MultinomialNB()).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.1.2. Classifier evaluation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = classifier_mnb.predict(X_test)\n",
    "\n",
    "classifier_mnb_score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy score for MNB classifier composed with OvR: {0:1.2F} %\".format(classifier_mnb_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['MNB'] = classifier_mnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.2. Chained Multinomial Naive Bayes classifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.2.1. Training Chained Naive Bayes classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#from nltk.classify import NaiveBayesClassifier\n",
    "#from sklearn.multioutput import ClassifierChain\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.linear_model import LogisticRegression\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chained_classifier_mnb = ClassifierChain(MultinomialNB())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chained_classifier_mnb.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "file_name='./data/chained_classifier_mnb.dump'\n",
    "p5_util.object_dump(chained_classifier_mnb, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.2.2. Chained classifier evaluation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "file_name='./data/chained_classifier_mnb.dump'\n",
    "chained_classifier_mnb = p5_util.object_load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape,y_test.shape)\n",
    "test_size=int(X_test.shape[0]/50)\n",
    "X_test_size = X_test[:test_size,:]\n",
    "y_test_size = y_test[:test_size,:]\n",
    "print(X_test_size.shape, y_test_size.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chained_classifier_mnb_score = chained_classifier_mnb.score(X_test_size ,y_test_size)\n",
    "\n",
    "print(\"Mean score for Chained Multinomial Naive Bayes classifier : {0:1.2F} %\".format(chained_classifier_mnb_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = classifier_mnb_chained.predict(X_test_size)\n",
    "\n",
    "chained_classifier_mnb_score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy score for chained MNB classifier : {0:1.2F} %\".format(score*100))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This result is not better then the one with OvR (binary relevance) transformation.\n",
    "\n",
    "It then can be suspected that Labels are independants from each other."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['Chained MNB'] = chained_classifier_mnb_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.3. Evaluation of Multinomial Bernouilli Naive Bayes classifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Data have binaries values? Bernouilli naive Bayes classifier is expected to provide good results."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "It is revealed that `y_train` is encoded as a binary array.\n",
    "\n",
    "It is then possible to arrange classifier as chained Binaries classifiers.\n",
    "\n",
    "Chaining binaries classifiers leads to take into account correlations between Labels assigned to samples.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.3.1. Training classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "classifier_ber = OneVsRestClassifier(BernoulliNB(), n_jobs=N_JOBS).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.3.2. Classifier evaluation </font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = classifier_ber.predict(X_test)\n",
    "\n",
    "classifier_ber_score = accuracy_score(y_test,y_pred)\n",
    "\n",
    "print(\"Accuracy score for Bernoilli NB classifier : {0:1.2F} %\".format(classifier_ber_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['Bernouilli NB'] = classifier_ber_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.4. Evaluation of SGD classifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from sklearn.multiclass import OneVsRestClassifier\n",
    "\n",
    "classifier_sgd = OneVsRestClassifier(SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None)).fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "classifier_sgd_score = classifier_sgd.score(X_test ,y_test)\n",
    "print(\"Mean score for Stochastic Gradient Descent classifier : {0:1.2F} %\".format(classifier_sgd_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['SGD'] = classifier_sgd_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "file_name='./data/dict_classifer_score.dump'\n",
    "p5_util.object_dump(dict_classifer_score, file_name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.5. Chained evaluation of SGD classifier</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Stochastic Gradient Descent Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultilearn.problem_transform import ClassifierChain\n",
    "\n",
    "#\n",
    "chained_classifier_sgd = ClassifierChain(SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(23149, 47236)"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X_train.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "The number of classes has to be greater than one; got 1 class",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-8-5eaa9c50d3a1>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mchained_classifier_sgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skmultilearn/problem_transform/cc.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, order)\u001b[0m\n\u001b[1;32m    153\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    154\u001b[0m             self.classifiers_[label] = self.classifier.fit(self._ensure_input_format(\n\u001b[0;32m--> 155\u001b[0;31m                 X_extended), self._ensure_output_format(y_subset))\n\u001b[0m\u001b[1;32m    156\u001b[0m             \u001b[0mX_extended\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhstack\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mX_extended\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_subset\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    712\u001b[0m                          \u001b[0mloss\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mloss\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlearning_rate\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlearning_rate\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    713\u001b[0m                          \u001b[0mcoef_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcoef_init\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mintercept_init\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mintercept_init\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 714\u001b[0;31m                          sample_weight=sample_weight)\n\u001b[0m\u001b[1;32m    715\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    716\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, coef_init, intercept_init, sample_weight)\u001b[0m\n\u001b[1;32m    570\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    571\u001b[0m         self._partial_fit(X, y, alpha, C, loss, learning_rate, self._max_iter,\n\u001b[0;32m--> 572\u001b[0;31m                           classes, sample_weight, coef_init, intercept_init)\n\u001b[0m\u001b[1;32m    573\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    574\u001b[0m         if (self._tol is not None and self._tol > -np.inf\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/stochastic_gradient.py\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, alpha, C, loss, learning_rate, max_iter, classes, sample_weight, coef_init, intercept_init)\u001b[0m\n\u001b[1;32m    533\u001b[0m             raise ValueError(\n\u001b[1;32m    534\u001b[0m                 \u001b[0;34m\"The number of classes has to be greater than one;\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m                 \" got %d class\" % n_classes)\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: The number of classes has to be greater than one; got 1 class"
     ]
    }
   ],
   "source": [
    "chained_classifier_sgd.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape,y_test.shape)\n",
    "test_size=int(X_test.shape[0]/50)\n",
    "X_test_size = X_test[:test_size,:]\n",
    "y_test_size = y_test[:test_size,:]\n",
    "print(X_test_size.shape, y_test_size.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "chained_classifier_sgd_score = classifier_sgd.score(X_test ,y_test)\n",
    "print(\"Mean score for Stochastic Gradient Descent classifier : {0:1.2F} %\".format(chained_classifier_sgd_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import p5_util\n",
    "file_name='./data/dict_classifer_score.dump'\n",
    "dict_classifer_score = p5_util.object_load(file_name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['Chained SGD'] = chained_classifier_sgd_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>2.5. SGD classfier transformed with Label powerset</font>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### <font color='blus'>2.5.1. Training classifier</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import SGDClassifier\n",
    "from skmultilearn.problem_transform import LabelPowerset\n",
    "power_classifier_sgd = LabelPowerset(SGDClassifier(loss='hinge', penalty='l2', alpha=1e-3, random_state=42, max_iter=5, tol=None))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "ename": "MemoryError",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mMemoryError\u001b[0m                               Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-10-3604bcd7af58>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mpower_classifier_sgd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m \u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skmultilearn/problem_transform/lp.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y)\u001b[0m\n\u001b[1;32m    138\u001b[0m             X, sparse_format='csr', enforce_sparse=True)\n\u001b[1;32m    139\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 140\u001b[0;31m         self.classifier.fit(self._ensure_input_format(X),\n\u001b[0m\u001b[1;32m    141\u001b[0m                             self.transform(y))\n\u001b[1;32m    142\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/skmultilearn/base/base.py\u001b[0m in \u001b[0;36m_ensure_input_format\u001b[0;34m(self, X, sparse_format, enforce_sparse)\u001b[0m\n\u001b[1;32m     84\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     85\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrequire_dense\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0menforce_sparse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 86\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     87\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     88\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0msparse_format\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/compressed.py\u001b[0m in \u001b[0;36mtoarray\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m    945\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mout\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0morder\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    946\u001b[0m             \u001b[0morder\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_swap\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'cf'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 947\u001b[0;31m         \u001b[0mout\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_process_toarray_args\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    948\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mc_contiguous\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflags\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mf_contiguous\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    949\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'Output array must be C or F contiguous'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.7/site-packages/scipy/sparse/base.py\u001b[0m in \u001b[0;36m_process_toarray_args\u001b[0;34m(self, order, out)\u001b[0m\n\u001b[1;32m   1182\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0mout\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1183\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1184\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mnp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzeros\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mshape\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdtype\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdtype\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0morder\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0morder\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1185\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1186\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mMemoryError\u001b[0m: "
     ]
    }
   ],
   "source": [
    "power_classifier_sgd.fit(X_train , y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(X_test.shape,y_test.shape)\n",
    "test_size=int(X_test.shape[0]/50)\n",
    "X_test_size = X_test[:test_size,:]\n",
    "y_test_size = y_test[:test_size,:]\n",
    "print(X_test_size.shape, y_test_size.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "y_pred = classifier_ber.predict(X_test_size)\n",
    "\n",
    "power_classifier_sgd_score = accuracy_score(y_test_size,y_pred)\n",
    "\n",
    "print(\"Accuracy score for Power labelled SGD classifier : {0:1.2F} %\".format(power_classifier_sgd_score*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dict_classifer_score['Power SGD'] = power_classifier_sgd_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## <font color='blus'>3. Classifiers results</font>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#-------------------------------------------------------------------------------\n",
    "#\n",
    "#-------------------------------------------------------------------------------\n",
    "def ser_item_occurency_plot(ser_item_name, ser_item_count, item_count=None, title=None):\n",
    "    \"\"\"Plot values issued form 2 Series as following : \n",
    "    First Series contains items names\n",
    "    Second Series contains items occutencies.\n",
    "    \n",
    "    \"\"\"\n",
    "    df_item_dict={item:count for item, count \\\n",
    "    in zip(ser_item_name, ser_item_count)}\n",
    "\n",
    "    list_item_sorted \\\n",
    "    = sorted(df_item_dict.items(), key=lambda x: x[1], reverse=False)\n",
    "\n",
    "    dict_item_sorted = dict()\n",
    "    for tuple_value in list_item_sorted :\n",
    "        dict_item_sorted[tuple_value[0]] = tuple_value[1]\n",
    "\n",
    "\n",
    "    X = list(dict_item_sorted.keys())\n",
    "    y = list(dict_item_sorted.values())\n",
    "\n",
    "    fig, ax = plt.subplots(figsize=(20,10))\n",
    "\n",
    "    if item_count is not None:\n",
    "        X_plot = X[:item_count]\n",
    "        y_plot = y[:item_count]\n",
    "    else:\n",
    "        X_plot = X.copy()\n",
    "        y_plot = y.copy()\n",
    "    \n",
    "    ax.plot(X_plot,y_plot)\n",
    "    ax.set_xticklabels(X[:item_count], rotation=90)\n",
    "    ax.set_xlabel('Accuracy')\n",
    "    ax.set_ylabel('Classifiers')\n",
    "    if title is not None : \n",
    "        ax.set_title(title)\n",
    "    ax.grid(linestyle='-', linewidth='0.1', color='grey')\n",
    "    fig.patch.set_facecolor('#E0E0E0')\n",
    "\n",
    "    plt.show()\n",
    "#-------------------------------------------------------------------------------\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Dictionary is sorted.**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "df_result = pd.DataFrame.from_dict( dict_classifer_score, orient='index')\n",
    "df_result.reset_index(inplace=True)\n",
    "df_result.rename(columns={'index':'Classifier',0:'Score'}, inplace=True)\n",
    "df_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "title = \"Classifiers accuracy\"\n",
    "ser_item_occurency_plot(df_result.Classifier, df_result.Score, item_count=None, title=title)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
